Investigating use case single_imagenet with server type honest_but_curious.
Files already downloaded and verified
Model architecture resnet50 loaded with 35,280,053 parameters and 53,173 buffers.
Overall this is a data ratio of     234:1 for target shape [1, 3, 224, 224] given that num_queries=1.
User (of type UserMultiStep) with settings:
    Number of data points: 1

    Threat model:
    User provides labels: False
    User provides buffers: False
    User provides number of data points: True

    Data:
    Dataset: LFWPeople
    user: 0
    
        
    Local FL Setup:
        Number of local update steps: 4
        Data per local update step: 1
        Local learning rate: 0.001

        Threat model:
        Share these hyperparams to server: True

        
Server (of type HonestServer) with settings:
    Threat model: Honest-but-curious
    Number of planned queries: 1
    Has external/public data: False

    Model:
        model specification: resnet50
        model state: default
        public buffers: True

    Secrets: {}
    
Attacker (of type OptimizationBasedAttacker) with settings:
    Hyperparameter Template: invertinggradients

    Objective: Cosine Similarity with scale=1.0 and task reg=0.0
    Regularizers: Total Variation, scale=0.005. p=1 q=1. 
    Augmentations: 

    Optimization Setup:
        optimizer: adam
        signed: hard
        step_size: 0.1
        boxed: True
        max_iterations: 32000
        step_size_decay: step-lr
        langevin_noise: 0.0
        warmup: 100
        grad_clip: None
        callback: 1000
        
Computing user update on user 0 in model mode: eval.
Saved to /user/gparrella/breaching/my_test/optimization_based/inverting_gradients/results/vggface_original.jpg
Reconstructing user data...
Files already downloaded and verified
Recovered labels [1161] through strategy yin.
| It: 1 | Rec. loss: 0.1745 |  Task loss: 0.0000 | T: 12.20s
| It: 1001 | Rec. loss: 0.0138 |  Task loss: 0.0000 | T: 1291.63s
| It: 2001 | Rec. loss: 0.0145 |  Task loss: 0.0000 | T: 1689.35s
| It: 3001 | Rec. loss: 0.0138 |  Task loss: 0.0000 | T: 1703.29s
| It: 4001 | Rec. loss: 0.0147 |  Task loss: 0.0000 | T: 1607.59s
| It: 5001 | Rec. loss: 0.0138 |  Task loss: 0.0000 | T: 1109.83s
| It: 6001 | Rec. loss: 0.0144 |  Task loss: 0.0000 | T: 1105.50s
| It: 7001 | Rec. loss: 0.0151 |  Task loss: 0.0000 | T: 1101.33s
| It: 8001 | Rec. loss: 0.0138 |  Task loss: 0.0000 | T: 1333.13s
| It: 9001 | Rec. loss: 0.0142 |  Task loss: 0.0000 | T: 1747.83s
| It: 10001 | Rec. loss: 0.0139 |  Task loss: 0.0000 | T: 1733.02s
| It: 11001 | Rec. loss: 0.0140 |  Task loss: 0.0000 | T: 1752.11s
| It: 12001 | Rec. loss: 0.0143 |  Task loss: 0.0000 | T: 1398.06s
| It: 13001 | Rec. loss: 0.0137 |  Task loss: 0.0000 | T: 1100.93s
| It: 14001 | Rec. loss: 0.0137 |  Task loss: 0.0000 | T: 1106.01s
| It: 15001 | Rec. loss: 0.0136 |  Task loss: 0.0000 | T: 1110.24s
