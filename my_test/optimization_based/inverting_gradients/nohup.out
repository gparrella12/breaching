Investigating use case single_imagenet with server type honest_but_curious.
Model architecture resnet50 loaded with 25,549,352 parameters and 53,173 buffers.
Overall this is a data ratio of     170:1 for target shape [1, 3, 224, 224] given that num_queries=1.
User (of type UserMultiStep) with settings:
    Number of data points: 1

    Threat model:
    User provides labels: False
    User provides buffers: False
    User provides number of data points: True

    Data:
    Dataset: flickr_faces
    user: 0
    
        
    Local FL Setup:
        Number of local update steps: 4
        Data per local update step: 1
        Local learning rate: 0.001

        Threat model:
        Share these hyperparams to server: True

        
Server (of type HonestServer) with settings:
    Threat model: Honest-but-curious
    Number of planned queries: 1
    Has external/public data: False

    Model:
        model specification: resnet50
        model state: default
        public buffers: True

    Secrets: {}
    
Attacker (of type OptimizationBasedAttacker) with settings:
    Hyperparameter Template: invertinggradients

    Objective: Cosine Similarity with scale=1.0 and task reg=0.0
    Regularizers: Total Variation, scale=0.005. p=1 q=1. 
    Augmentations: 

    Optimization Setup:
        optimizer: adam
        signed: hard
        step_size: 0.1
        boxed: True
        max_iterations: 32000
        step_size_decay: step-lr
        langevin_noise: 0.0
        warmup: 100
        grad_clip: None
        callback: 1000
        
Computing user update on user 0 in model mode: eval.
Saved to /user/gparrella/breaching/my_test/optimization_based/inverting_gradients/results/flickr_original.jpg
Reconstructing user data...
Files already downloaded and verified
Recovered labels [60] through strategy yin.
| It: 1 | Rec. loss: 0.0216 |  Task loss: 0.0000 | T: 10.74s
| It: 1001 | Rec. loss: 0.0061 |  Task loss: 0.0000 | T: 1132.77s
| It: 2001 | Rec. loss: 0.0057 |  Task loss: 0.0000 | T: 1130.64s
| It: 3001 | Rec. loss: 0.0059 |  Task loss: 0.0000 | T: 1126.15s
| It: 4001 | Rec. loss: 0.0056 |  Task loss: 0.0000 | T: 1131.94s
| It: 5001 | Rec. loss: 0.0060 |  Task loss: 0.0000 | T: 1132.29s
| It: 6001 | Rec. loss: 0.0064 |  Task loss: 0.0000 | T: 1133.18s
| It: 7001 | Rec. loss: 0.0066 |  Task loss: 0.0000 | T: 1133.33s
| It: 8001 | Rec. loss: 0.0071 |  Task loss: 0.0000 | T: 1130.45s
| It: 9001 | Rec. loss: 0.0066 |  Task loss: 0.0000 | T: 1168.71s
| It: 10001 | Rec. loss: 0.0073 |  Task loss: 0.0000 | T: 1765.21s
| It: 11001 | Rec. loss: 0.0094 |  Task loss: 0.0000 | T: 1814.67s
| It: 12001 | Rec. loss: 0.0077 |  Task loss: 0.0000 | T: 1777.11s
| It: 13001 | Rec. loss: 0.0062 |  Task loss: 0.0000 | T: 1767.54s
| It: 14001 | Rec. loss: 0.0052 |  Task loss: 0.0000 | T: 1769.66s
| It: 15001 | Rec. loss: 0.0073 |  Task loss: 0.0000 | T: 1776.28s
