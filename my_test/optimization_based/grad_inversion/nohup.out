Trial 0

Investigating use case small_batch_imagenet with server type honest_but_curious.
Seed: 87371
Model architecture vggface2 loaded with 27,910,327 parameters and 29,712 buffers.
Overall this is a data ratio of      12:1 for target shape [16, 3, 224, 224] given that num_queries=1.
User (of type UserSingleStep) with settings:
    Number of data points: 16

    Threat model:
    User provides labels: False
    User provides buffers: True
    User provides number of data points: True

    Data:
    Dataset: flickr_faces
    user: 0
    
        
Server (of type HonestServer) with settings:
    Threat model: Honest-but-curious
    Number of planned queries: 1
    Has external/public data: False

    Model:
        model specification: vggface2
        model state: default
        public buffers: False

    Secrets: {}
    
Attacker (of type OptimizationBasedAttacker) with settings:
    Hyperparameter Template: see-through-gradients

    Objective: Euclidean loss with scale=0.0001 and task reg=0.0
    Regularizers: Total Variation, scale=0.0001. p=1 q=1. 
                  Input L^p norm regularization, scale=1e-06, p=2
                  Deep Inversion Regularization (matching batch norms), scale=0.1, first-bn-mult=10
    Augmentations: 

    Optimization Setup:
        optimizer: adam
        signed: False
        step_size: 0.1
        boxed: True
        max_iterations: 320000
        step_size_decay: cosine-decay
        langevin_noise: 0.01
        warmup: 100
        grad_clip: None
        callback: 1000
        
Computing user update on user 0 in model mode: training.
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_pre0.png
Reconstructing user data...
Files already downloaded and verified
initial data len: 16
Recovered labels [172, 202, 223, 274, 297, 311, 331, 451, 465, 556, 692, 699, 702, 738, 809, 825] through strategy yin.
| It: 1 | Rec. loss: 31.1366 |  Task loss: 10.6332 | T: 2.87s
| It: 1001 | Rec. loss: 13.1735 |  Task loss: 3.3704 | T: 294.08s
| It: 2001 | Rec. loss: 10.5812 |  Task loss: 2.3239 | T: 287.91s
| It: 3001 | Rec. loss: 10.2903 |  Task loss: 1.4217 | T: 286.39s
| It: 4001 | Rec. loss: 10.1948 |  Task loss: 1.3172 | T: 287.19s
| It: 5001 | Rec. loss: 10.1626 |  Task loss: 1.3293 | T: 292.25s
| It: 6001 | Rec. loss: 10.0937 |  Task loss: 1.1025 | T: 284.81s
| It: 7001 | Rec. loss: 10.0857 |  Task loss: 1.0508 | T: 285.24s
| It: 8001 | Rec. loss: 10.0848 |  Task loss: 0.8782 | T: 289.73s
| It: 9001 | Rec. loss: 10.0593 |  Task loss: 0.9351 | T: 289.72s
| It: 10001 | Rec. loss: 10.0395 |  Task loss: 0.8994 | T: 284.59s
| It: 11001 | Rec. loss: 10.0209 |  Task loss: 0.5971 | T: 287.44s
| It: 12001 | Rec. loss: 9.9967 |  Task loss: 0.6089 | T: 294.95s
| It: 13001 | Rec. loss: 9.9922 |  Task loss: 0.6315 | T: 283.96s
| It: 14001 | Rec. loss: 9.9726 |  Task loss: 0.6169 | T: 285.94s
| It: 15001 | Rec. loss: 10.0188 |  Task loss: 0.6272 | T: 287.48s
| It: 16001 | Rec. loss: 9.9640 |  Task loss: 0.5813 | T: 285.48s
| It: 17001 | Rec. loss: 9.9770 |  Task loss: 0.6149 | T: 284.91s
| It: 18001 | Rec. loss: 9.9433 |  Task loss: 0.5619 | T: 282.38s
| It: 19001 | Rec. loss: 9.9370 |  Task loss: 0.5736 | T: 286.43s
| It: 20001 | Rec. loss: 9.9280 |  Task loss: 0.6072 | T: 285.71s
| It: 21001 | Rec. loss: 9.9288 |  Task loss: 0.5857 | T: 285.53s
| It: 22001 | Rec. loss: 9.9038 |  Task loss: 0.5818 | T: 282.45s
| It: 23001 | Rec. loss: 9.9218 |  Task loss: 0.5728 | T: 282.11s
| It: 24001 | Rec. loss: 9.9121 |  Task loss: 0.5955 | T: 283.53s
| It: 25001 | Rec. loss: 9.8810 |  Task loss: 0.5794 | T: 282.12s
| It: 26001 | Rec. loss: 9.8735 |  Task loss: 0.5247 | T: 282.94s
| It: 27001 | Rec. loss: 9.8505 |  Task loss: 0.5750 | T: 285.28s
| It: 28001 | Rec. loss: 9.8655 |  Task loss: 0.5825 | T: 287.59s
| It: 29001 | Rec. loss: 9.8236 |  Task loss: 0.6147 | T: 294.00s
| It: 30001 | Rec. loss: 9.8257 |  Task loss: 0.5779 | T: 282.95s
| It: 31001 | Rec. loss: 9.8182 |  Task loss: 0.5726 | T: 293.51s
| It: 32001 | Rec. loss: 9.7919 |  Task loss: 0.5629 | T: 287.10s
| It: 33001 | Rec. loss: 9.8012 |  Task loss: 0.5996 | T: 286.60s
| It: 34001 | Rec. loss: 9.7772 |  Task loss: 0.5539 | T: 284.44s
| It: 35001 | Rec. loss: 9.7667 |  Task loss: 0.5211 | T: 286.37s
| It: 36001 | Rec. loss: 9.7656 |  Task loss: 0.4949 | T: 284.76s
| It: 37001 | Rec. loss: 9.7569 |  Task loss: 0.5582 | T: 281.91s
| It: 38001 | Rec. loss: 9.7495 |  Task loss: 0.5424 | T: 282.31s
| It: 39001 | Rec. loss: 9.7099 |  Task loss: 0.4676 | T: 281.74s
| It: 40001 | Rec. loss: 9.7153 |  Task loss: 0.4886 | T: 287.02s
| It: 41001 | Rec. loss: 9.7207 |  Task loss: 0.4823 | T: 280.86s
| It: 42001 | Rec. loss: 9.6859 |  Task loss: 0.5587 | T: 279.38s
| It: 43001 | Rec. loss: 9.6959 |  Task loss: 0.4789 | T: 282.90s
| It: 44001 | Rec. loss: 9.6980 |  Task loss: 0.5036 | T: 280.28s
| It: 45001 | Rec. loss: 9.6618 |  Task loss: 0.5071 | T: 283.25s
| It: 46001 | Rec. loss: 9.6628 |  Task loss: 0.4843 | T: 290.18s
| It: 47001 | Rec. loss: 9.6714 |  Task loss: 0.4640 | T: 293.56s
| It: 48001 | Rec. loss: 9.6367 |  Task loss: 0.4711 | T: 250.42s
| It: 49001 | Rec. loss: 9.6178 |  Task loss: 0.4848 | T: 250.03s
| It: 50001 | Rec. loss: 9.6060 |  Task loss: 0.4493 | T: 248.54s
| It: 51001 | Rec. loss: 9.6003 |  Task loss: 0.4490 | T: 249.16s
| It: 52001 | Rec. loss: 9.5631 |  Task loss: 0.4624 | T: 249.94s
| It: 53001 | Rec. loss: 9.5639 |  Task loss: 0.4734 | T: 248.04s
| It: 54001 | Rec. loss: 9.5630 |  Task loss: 0.4561 | T: 247.84s
| It: 55001 | Rec. loss: 9.5202 |  Task loss: 0.5094 | T: 248.70s
| It: 56001 | Rec. loss: 9.5089 |  Task loss: 0.4934 | T: 247.17s
| It: 57001 | Rec. loss: 9.4868 |  Task loss: 0.4923 | T: 254.28s
| It: 58001 | Rec. loss: 9.4830 |  Task loss: 0.5257 | T: 252.17s
| It: 59001 | Rec. loss: 9.4930 |  Task loss: 0.4970 | T: 256.56s
| It: 60001 | Rec. loss: 9.4711 |  Task loss: 0.4976 | T: 256.39s
| It: 61001 | Rec. loss: 9.4391 |  Task loss: 0.5049 | T: 256.44s
| It: 62001 | Rec. loss: 9.4166 |  Task loss: 0.5072 | T: 256.54s
| It: 63001 | Rec. loss: 9.4055 |  Task loss: 0.4864 | T: 256.37s
| It: 64001 | Rec. loss: 9.3951 |  Task loss: 0.5060 | T: 256.54s
| It: 65001 | Rec. loss: 9.3596 |  Task loss: 0.4770 | T: 256.36s
| It: 66001 | Rec. loss: 9.3476 |  Task loss: 0.5030 | T: 256.68s
| It: 67001 | Rec. loss: 9.3402 |  Task loss: 0.5312 | T: 258.74s
| It: 68001 | Rec. loss: 9.3109 |  Task loss: 0.5026 | T: 258.64s
| It: 69001 | Rec. loss: 9.3033 |  Task loss: 0.4783 | T: 258.69s
| It: 70001 | Rec. loss: 9.2518 |  Task loss: 0.5025 | T: 258.60s
| It: 71001 | Rec. loss: 9.2553 |  Task loss: 0.4630 | T: 256.70s
| It: 72001 | Rec. loss: 9.2429 |  Task loss: 0.5139 | T: 256.69s
| It: 73001 | Rec. loss: 9.2187 |  Task loss: 0.5106 | T: 257.33s
| It: 74001 | Rec. loss: 9.2280 |  Task loss: 0.5021 | T: 258.57s
| It: 75001 | Rec. loss: 9.1925 |  Task loss: 0.4830 | T: 258.54s
| It: 76001 | Rec. loss: 9.1440 |  Task loss: 0.4749 | T: 256.54s
| It: 77001 | Rec. loss: 9.1404 |  Task loss: 0.4950 | T: 256.62s
| It: 78001 | Rec. loss: 9.0970 |  Task loss: 0.5196 | T: 256.64s
| It: 79001 | Rec. loss: 9.0891 |  Task loss: 0.4846 | T: 256.66s
| It: 80001 | Rec. loss: 9.0754 |  Task loss: 0.4725 | T: 256.66s
| It: 81001 | Rec. loss: 9.0465 |  Task loss: 0.4730 | T: 256.63s
| It: 82001 | Rec. loss: 9.0184 |  Task loss: 0.4768 | T: 256.49s
| It: 83001 | Rec. loss: 9.0106 |  Task loss: 0.4816 | T: 256.66s
| It: 84001 | Rec. loss: 8.9992 |  Task loss: 0.4919 | T: 258.03s
| It: 85001 | Rec. loss: 8.9566 |  Task loss: 0.4868 | T: 258.20s
| It: 86001 | Rec. loss: 8.9391 |  Task loss: 0.5055 | T: 258.42s
| It: 87001 | Rec. loss: 8.9006 |  Task loss: 0.5081 | T: 258.38s
| It: 88001 | Rec. loss: 8.9187 |  Task loss: 0.4771 | T: 258.56s
| It: 89001 | Rec. loss: 8.8567 |  Task loss: 0.4400 | T: 258.53s
| It: 90001 | Rec. loss: 8.8326 |  Task loss: 0.4538 | T: 258.33s
| It: 91001 | Rec. loss: 8.8137 |  Task loss: 0.4847 | T: 258.56s
| It: 92001 | Rec. loss: 8.7753 |  Task loss: 0.4421 | T: 258.50s
| It: 93001 | Rec. loss: 8.7552 |  Task loss: 0.4632 | T: 258.12s
| It: 94001 | Rec. loss: 8.7146 |  Task loss: 0.4585 | T: 258.25s
| It: 95001 | Rec. loss: 8.7045 |  Task loss: 0.4543 | T: 258.36s
| It: 96001 | Rec. loss: 8.6959 |  Task loss: 0.4757 | T: 258.57s
| It: 97001 | Rec. loss: 8.6953 |  Task loss: 0.4715 | T: 258.11s
| It: 98001 | Rec. loss: 8.6188 |  Task loss: 0.5141 | T: 258.14s
| It: 99001 | Rec. loss: 8.6047 |  Task loss: 0.5199 | T: 257.82s
| It: 100001 | Rec. loss: 8.5789 |  Task loss: 0.4519 | T: 258.22s
| It: 101001 | Rec. loss: 8.5240 |  Task loss: 0.4550 | T: 258.17s
| It: 102001 | Rec. loss: 8.5042 |  Task loss: 0.4968 | T: 258.27s
| It: 103001 | Rec. loss: 8.4765 |  Task loss: 0.4847 | T: 258.12s
| It: 104001 | Rec. loss: 8.4268 |  Task loss: 0.4976 | T: 258.33s
| It: 105001 | Rec. loss: 8.4350 |  Task loss: 0.4680 | T: 258.26s
| It: 106001 | Rec. loss: 8.3828 |  Task loss: 0.4909 | T: 258.43s
| It: 107001 | Rec. loss: 8.3644 |  Task loss: 0.4681 | T: 257.91s
| It: 108001 | Rec. loss: 8.3243 |  Task loss: 0.4749 | T: 258.21s
| It: 109001 | Rec. loss: 8.2844 |  Task loss: 0.4675 | T: 257.77s
| It: 110001 | Rec. loss: 8.2518 |  Task loss: 0.4643 | T: 257.90s
| It: 111001 | Rec. loss: 8.2120 |  Task loss: 0.4456 | T: 258.04s
| It: 112001 | Rec. loss: 8.1898 |  Task loss: 0.4336 | T: 258.06s
| It: 113001 | Rec. loss: 8.1386 |  Task loss: 0.4561 | T: 258.25s
| It: 114001 | Rec. loss: 8.1417 |  Task loss: 0.4773 | T: 258.18s
| It: 115001 | Rec. loss: 8.0765 |  Task loss: 0.4268 | T: 258.21s
| It: 116001 | Rec. loss: 8.0355 |  Task loss: 0.4097 | T: 258.31s
| It: 117001 | Rec. loss: 8.0234 |  Task loss: 0.4204 | T: 258.10s
| It: 118001 | Rec. loss: 7.9824 |  Task loss: 0.4596 | T: 258.26s
| It: 119001 | Rec. loss: 7.9431 |  Task loss: 0.4625 | T: 258.35s
| It: 120001 | Rec. loss: 7.9304 |  Task loss: 0.4467 | T: 258.15s
| It: 121001 | Rec. loss: 7.8694 |  Task loss: 0.4372 | T: 258.25s
| It: 122001 | Rec. loss: 7.8292 |  Task loss: 0.4362 | T: 258.55s
| It: 123001 | Rec. loss: 7.7986 |  Task loss: 0.4527 | T: 258.09s
| It: 124001 | Rec. loss: 7.7395 |  Task loss: 0.4878 | T: 258.43s
| It: 125001 | Rec. loss: 7.7074 |  Task loss: 0.4502 | T: 258.45s
| It: 126001 | Rec. loss: 7.6779 |  Task loss: 0.4987 | T: 258.31s
| It: 127001 | Rec. loss: 7.6206 |  Task loss: 0.4582 | T: 258.31s
| It: 128001 | Rec. loss: 7.6001 |  Task loss: 0.4426 | T: 258.35s
| It: 129001 | Rec. loss: 7.5440 |  Task loss: 0.4633 | T: 258.40s
| It: 130001 | Rec. loss: 7.5064 |  Task loss: 0.4537 | T: 258.45s
| It: 131001 | Rec. loss: 7.4613 |  Task loss: 0.4278 | T: 258.13s
| It: 132001 | Rec. loss: 7.4248 |  Task loss: 0.4163 | T: 258.26s
| It: 133001 | Rec. loss: 7.3662 |  Task loss: 0.4056 | T: 258.39s
| It: 134001 | Rec. loss: 7.3462 |  Task loss: 0.3850 | T: 258.28s
| It: 135001 | Rec. loss: 7.2806 |  Task loss: 0.3859 | T: 258.30s
| It: 136001 | Rec. loss: 7.2581 |  Task loss: 0.4017 | T: 258.33s
| It: 137001 | Rec. loss: 7.1937 |  Task loss: 0.4318 | T: 258.36s
| It: 138001 | Rec. loss: 7.1577 |  Task loss: 0.3974 | T: 258.17s
| It: 139001 | Rec. loss: 7.1177 |  Task loss: 0.3929 | T: 257.79s
| It: 140001 | Rec. loss: 7.0591 |  Task loss: 0.3833 | T: 257.78s
| It: 141001 | Rec. loss: 7.0161 |  Task loss: 0.3705 | T: 257.66s
| It: 142001 | Rec. loss: 6.9776 |  Task loss: 0.4064 | T: 257.75s
| It: 143001 | Rec. loss: 6.9534 |  Task loss: 0.3892 | T: 257.67s
| It: 144001 | Rec. loss: 6.8578 |  Task loss: 0.3786 | T: 257.88s
| It: 145001 | Rec. loss: 6.8402 |  Task loss: 0.3756 | T: 258.06s
| It: 146001 | Rec. loss: 6.7661 |  Task loss: 0.4066 | T: 257.91s
| It: 147001 | Rec. loss: 6.7063 |  Task loss: 0.4007 | T: 257.88s
| It: 148001 | Rec. loss: 6.6650 |  Task loss: 0.4199 | T: 257.78s
| It: 149001 | Rec. loss: 6.6227 |  Task loss: 0.4095 | T: 257.33s
| It: 150001 | Rec. loss: 6.5583 |  Task loss: 0.4182 | T: 257.98s
| It: 151001 | Rec. loss: 6.5159 |  Task loss: 0.4436 | T: 257.97s
| It: 152001 | Rec. loss: 6.4641 |  Task loss: 0.4131 | T: 257.85s
| It: 153001 | Rec. loss: 6.4157 |  Task loss: 0.3851 | T: 257.51s
| It: 154001 | Rec. loss: 6.3505 |  Task loss: 0.4313 | T: 256.80s
| It: 155001 | Rec. loss: 6.3172 |  Task loss: 0.4407 | T: 256.40s
| It: 156001 | Rec. loss: 6.2473 |  Task loss: 0.4723 | T: 256.45s
| It: 157001 | Rec. loss: 6.1971 |  Task loss: 0.4613 | T: 257.20s
| It: 158001 | Rec. loss: 6.1504 |  Task loss: 0.4309 | T: 257.18s
| It: 159001 | Rec. loss: 6.0925 |  Task loss: 0.4459 | T: 257.24s
| It: 160001 | Rec. loss: 6.0350 |  Task loss: 0.4854 | T: 257.24s
| It: 161001 | Rec. loss: 5.9791 |  Task loss: 0.4589 | T: 256.74s
| It: 162001 | Rec. loss: 5.9207 |  Task loss: 0.4642 | T: 256.42s
| It: 163001 | Rec. loss: 5.8629 |  Task loss: 0.4991 | T: 256.32s
| It: 164001 | Rec. loss: 5.8410 |  Task loss: 0.4934 | T: 256.60s
| It: 165001 | Rec. loss: 5.7383 |  Task loss: 0.5198 | T: 257.19s
| It: 166001 | Rec. loss: 5.6838 |  Task loss: 0.4899 | T: 257.25s
| It: 167001 | Rec. loss: 5.6306 |  Task loss: 0.4741 | T: 257.12s
| It: 168001 | Rec. loss: 5.5705 |  Task loss: 0.4678 | T: 256.75s
| It: 169001 | Rec. loss: 5.5148 |  Task loss: 0.5048 | T: 256.42s
| It: 170001 | Rec. loss: 5.4580 |  Task loss: 0.4564 | T: 256.37s
| It: 171001 | Rec. loss: 5.3912 |  Task loss: 0.4953 | T: 256.36s
| It: 172001 | Rec. loss: 5.3353 |  Task loss: 0.5065 | T: 256.44s
| It: 173001 | Rec. loss: 5.2710 |  Task loss: 0.4693 | T: 256.77s
| It: 174001 | Rec. loss: 5.2131 |  Task loss: 0.4229 | T: 258.20s
| It: 175001 | Rec. loss: 5.1415 |  Task loss: 0.4459 | T: 257.07s
| It: 176001 | Rec. loss: 5.0770 |  Task loss: 0.4527 | T: 258.02s
| It: 177001 | Rec. loss: 5.0235 |  Task loss: 0.4395 | T: 256.60s
| It: 178001 | Rec. loss: 4.9519 |  Task loss: 0.4315 | T: 256.76s
| It: 179001 | Rec. loss: 4.8903 |  Task loss: 0.4237 | T: 257.24s
| It: 180001 | Rec. loss: 4.8295 |  Task loss: 0.4078 | T: 256.62s
| It: 181001 | Rec. loss: 4.7656 |  Task loss: 0.3955 | T: 257.42s
| It: 182001 | Rec. loss: 4.7070 |  Task loss: 0.3794 | T: 257.11s
| It: 183001 | Rec. loss: 4.6376 |  Task loss: 0.3763 | T: 257.12s
| It: 184001 | Rec. loss: 4.5652 |  Task loss: 0.3757 | T: 256.97s
| It: 185001 | Rec. loss: 4.5090 |  Task loss: 0.2747 | T: 257.05s
| It: 186001 | Rec. loss: 4.4282 |  Task loss: 0.1388 | T: 257.13s
| It: 187001 | Rec. loss: 4.3622 |  Task loss: 0.1282 | T: 256.71s
| It: 188001 | Rec. loss: 4.3007 |  Task loss: 0.1282 | T: 256.95s
| It: 189001 | Rec. loss: 4.2352 |  Task loss: 0.1246 | T: 257.00s
| It: 190001 | Rec. loss: 4.1539 |  Task loss: 0.1247 | T: 257.06s
| It: 191001 | Rec. loss: 4.0905 |  Task loss: 0.1269 | T: 257.32s
| It: 192001 | Rec. loss: 4.0241 |  Task loss: 0.1186 | T: 257.05s
| It: 193001 | Rec. loss: 3.9608 |  Task loss: 0.1202 | T: 256.25s
| It: 194001 | Rec. loss: 3.8922 |  Task loss: 0.1208 | T: 256.36s
| It: 195001 | Rec. loss: 3.8328 |  Task loss: 0.1233 | T: 257.09s
| It: 196001 | Rec. loss: 3.7629 |  Task loss: 0.1205 | T: 256.93s
| It: 197001 | Rec. loss: 3.6887 |  Task loss: 0.1183 | T: 257.03s
| It: 198001 | Rec. loss: 3.6307 |  Task loss: 0.1173 | T: 257.55s
| It: 199001 | Rec. loss: 3.5665 |  Task loss: 0.1186 | T: 257.87s
| It: 200001 | Rec. loss: 3.5022 |  Task loss: 0.1150 | T: 256.39s
| It: 201001 | Rec. loss: 3.4279 |  Task loss: 0.1128 | T: 256.40s
| It: 202001 | Rec. loss: 3.3624 |  Task loss: 0.1155 | T: 258.17s
| It: 203001 | Rec. loss: 3.2985 |  Task loss: 0.1196 | T: 256.62s
| It: 204001 | Rec. loss: 3.2432 |  Task loss: 0.1200 | T: 256.34s
| It: 205001 | Rec. loss: 3.1809 |  Task loss: 0.1134 | T: 256.37s
| It: 206001 | Rec. loss: 3.1150 |  Task loss: 0.1127 | T: 257.30s
| It: 207001 | Rec. loss: 3.0598 |  Task loss: 0.1136 | T: 259.62s
| It: 208001 | Rec. loss: 2.9940 |  Task loss: 0.1123 | T: 259.70s
| It: 209001 | Rec. loss: 2.9446 |  Task loss: 0.1086 | T: 259.63s
| It: 210001 | Rec. loss: 2.8823 |  Task loss: 0.1117 | T: 259.07s
| It: 211001 | Rec. loss: 2.8222 |  Task loss: 0.1094 | T: 259.75s
| It: 212001 | Rec. loss: 2.7720 |  Task loss: 0.1096 | T: 257.12s
| It: 213001 | Rec. loss: 2.7145 |  Task loss: 0.1051 | T: 256.51s
| It: 214001 | Rec. loss: 2.6625 |  Task loss: 0.1083 | T: 257.28s
| It: 215001 | Rec. loss: 2.6128 |  Task loss: 0.1055 | T: 257.50s
| It: 216001 | Rec. loss: 2.5633 |  Task loss: 0.1056 | T: 257.33s
| It: 217001 | Rec. loss: 2.5123 |  Task loss: 0.1017 | T: 257.01s
| It: 218001 | Rec. loss: 2.4653 |  Task loss: 0.1043 | T: 256.51s
| It: 219001 | Rec. loss: 2.4226 |  Task loss: 0.1048 | T: 257.08s
| It: 220001 | Rec. loss: 2.3672 |  Task loss: 0.1065 | T: 259.47s
| It: 221001 | Rec. loss: 2.3194 |  Task loss: 0.1055 | T: 259.69s
| It: 222001 | Rec. loss: 2.2725 |  Task loss: 0.1057 | T: 256.45s
| It: 223001 | Rec. loss: 2.2271 |  Task loss: 0.1028 | T: 256.57s
| It: 224001 | Rec. loss: 2.1825 |  Task loss: 0.1000 | T: 256.58s
| It: 225001 | Rec. loss: 2.1404 |  Task loss: 0.1026 | T: 257.79s
| It: 226001 | Rec. loss: 2.0918 |  Task loss: 0.1018 | T: 257.19s
| It: 227001 | Rec. loss: 2.0481 |  Task loss: 0.0999 | T: 257.56s
| It: 228001 | Rec. loss: 2.0020 |  Task loss: 0.0983 | T: 257.70s
| It: 229001 | Rec. loss: 1.9575 |  Task loss: 0.1015 | T: 259.60s
| It: 230001 | Rec. loss: 1.9210 |  Task loss: 0.0981 | T: 260.06s
| It: 231001 | Rec. loss: 1.8726 |  Task loss: 0.0974 | T: 259.63s
| It: 232001 | Rec. loss: 1.8370 |  Task loss: 0.0969 | T: 257.70s
| It: 233001 | Rec. loss: 1.7968 |  Task loss: 0.0965 | T: 256.61s
| It: 234001 | Rec. loss: 1.7577 |  Task loss: 0.0974 | T: 256.52s
| It: 235001 | Rec. loss: 1.7242 |  Task loss: 0.0933 | T: 256.74s
| It: 236001 | Rec. loss: 1.6814 |  Task loss: 0.0953 | T: 259.34s
| It: 237001 | Rec. loss: 1.6508 |  Task loss: 0.0934 | T: 260.05s
| It: 238001 | Rec. loss: 1.6153 |  Task loss: 0.0941 | T: 260.02s
| It: 239001 | Rec. loss: 1.5852 |  Task loss: 0.0939 | T: 260.01s
| It: 240001 | Rec. loss: 1.5523 |  Task loss: 0.0930 | T: 259.71s
| It: 241001 | Rec. loss: 1.5174 |  Task loss: 0.0912 | T: 259.31s
| It: 242001 | Rec. loss: 1.4860 |  Task loss: 0.0906 | T: 259.50s
| It: 243001 | Rec. loss: 1.4538 |  Task loss: 0.0917 | T: 260.08s
| It: 244001 | Rec. loss: 1.4224 |  Task loss: 0.0910 | T: 259.88s
| It: 245001 | Rec. loss: 1.3956 |  Task loss: 0.0902 | T: 259.88s
| It: 246001 | Rec. loss: 1.3635 |  Task loss: 0.0908 | T: 259.86s
| It: 247001 | Rec. loss: 1.3349 |  Task loss: 0.0896 | T: 259.26s
| It: 248001 | Rec. loss: 1.3073 |  Task loss: 0.0892 | T: 259.33s
| It: 249001 | Rec. loss: 1.2793 |  Task loss: 0.0882 | T: 258.59s
| It: 250001 | Rec. loss: 1.2565 |  Task loss: 0.0875 | T: 258.05s
| It: 251001 | Rec. loss: 1.2312 |  Task loss: 0.0877 | T: 258.14s
| It: 252001 | Rec. loss: 1.2030 |  Task loss: 0.0873 | T: 259.44s
| It: 253001 | Rec. loss: 1.1743 |  Task loss: 0.0867 | T: 259.29s
| It: 254001 | Rec. loss: 1.1526 |  Task loss: 0.0856 | T: 259.36s
| It: 255001 | Rec. loss: 1.1286 |  Task loss: 0.0857 | T: 259.30s
| It: 256001 | Rec. loss: 1.1048 |  Task loss: 0.0852 | T: 259.84s
| It: 257001 | Rec. loss: 1.0810 |  Task loss: 0.0842 | T: 259.48s
| It: 258001 | Rec. loss: 1.0612 |  Task loss: 0.0844 | T: 259.92s
| It: 259001 | Rec. loss: 1.0390 |  Task loss: 0.0836 | T: 259.97s
| It: 260001 | Rec. loss: 1.0157 |  Task loss: 0.0833 | T: 259.79s
| It: 261001 | Rec. loss: 0.9949 |  Task loss: 0.0828 | T: 259.85s
| It: 262001 | Rec. loss: 0.9742 |  Task loss: 0.0821 | T: 259.87s
| It: 263001 | Rec. loss: 0.9527 |  Task loss: 0.0817 | T: 258.68s
| It: 264001 | Rec. loss: 0.9330 |  Task loss: 0.0827 | T: 259.83s
| It: 265001 | Rec. loss: 0.9123 |  Task loss: 0.0819 | T: 258.64s
| It: 266001 | Rec. loss: 0.8942 |  Task loss: 0.0820 | T: 259.30s
| It: 267001 | Rec. loss: 0.8762 |  Task loss: 0.0817 | T: 259.88s
| It: 268001 | Rec. loss: 0.8555 |  Task loss: 0.0810 | T: 258.03s
| It: 269001 | Rec. loss: 0.8382 |  Task loss: 0.0804 | T: 257.33s
| It: 270001 | Rec. loss: 0.8209 |  Task loss: 0.0803 | T: 257.58s
| It: 271001 | Rec. loss: 0.8052 |  Task loss: 0.0807 | T: 257.82s
| It: 272001 | Rec. loss: 0.7872 |  Task loss: 0.0805 | T: 260.68s
| It: 273001 | Rec. loss: 0.7705 |  Task loss: 0.0804 | T: 258.93s
| It: 274001 | Rec. loss: 0.7553 |  Task loss: 0.0801 | T: 257.88s
| It: 275001 | Rec. loss: 0.7384 |  Task loss: 0.0795 | T: 258.09s
| It: 276001 | Rec. loss: 0.7249 |  Task loss: 0.0794 | T: 258.38s
| It: 277001 | Rec. loss: 0.7074 |  Task loss: 0.0789 | T: 258.02s
| It: 278001 | Rec. loss: 0.6957 |  Task loss: 0.0788 | T: 259.14s
| It: 279001 | Rec. loss: 0.6804 |  Task loss: 0.0788 | T: 257.97s
| It: 280001 | Rec. loss: 0.6694 |  Task loss: 0.0786 | T: 257.95s
| It: 281001 | Rec. loss: 0.6538 |  Task loss: 0.0782 | T: 257.84s
| It: 282001 | Rec. loss: 0.6431 |  Task loss: 0.0780 | T: 257.92s
| It: 283001 | Rec. loss: 0.6271 |  Task loss: 0.0774 | T: 257.76s
| It: 284001 | Rec. loss: 0.6130 |  Task loss: 0.0775 | T: 258.01s
| It: 285001 | Rec. loss: 0.6028 |  Task loss: 0.0770 | T: 257.70s
| It: 286001 | Rec. loss: 0.5899 |  Task loss: 0.0770 | T: 257.93s
| It: 287001 | Rec. loss: 0.5797 |  Task loss: 0.0768 | T: 258.22s
| It: 288001 | Rec. loss: 0.5675 |  Task loss: 0.0766 | T: 257.84s
| It: 289001 | Rec. loss: 0.5583 |  Task loss: 0.0769 | T: 258.10s
| It: 290001 | Rec. loss: 0.5467 |  Task loss: 0.0768 | T: 258.13s
| It: 291001 | Rec. loss: 0.5363 |  Task loss: 0.0763 | T: 257.88s
| It: 292001 | Rec. loss: 0.5267 |  Task loss: 0.0764 | T: 257.97s
| It: 293001 | Rec. loss: 0.5160 |  Task loss: 0.0765 | T: 258.25s
| It: 294001 | Rec. loss: 0.5077 |  Task loss: 0.0764 | T: 258.50s
| It: 295001 | Rec. loss: 0.5002 |  Task loss: 0.0762 | T: 258.15s
| It: 296001 | Rec. loss: 0.4911 |  Task loss: 0.0762 | T: 263.52s
| It: 297001 | Rec. loss: 0.4832 |  Task loss: 0.0763 | T: 262.27s
| It: 298001 | Rec. loss: 0.4784 |  Task loss: 0.0763 | T: 257.75s
| It: 299001 | Rec. loss: 0.4687 |  Task loss: 0.0763 | T: 257.81s
| It: 300001 | Rec. loss: 0.4620 |  Task loss: 0.0764 | T: 257.05s
| It: 301001 | Rec. loss: 0.4561 |  Task loss: 0.0763 | T: 256.60s
| It: 302001 | Rec. loss: 0.4504 |  Task loss: 0.0763 | T: 256.78s
| It: 303001 | Rec. loss: 0.4445 |  Task loss: 0.0764 | T: 256.67s
| It: 304001 | Rec. loss: 0.4397 |  Task loss: 0.0764 | T: 269.93s
| It: 305001 | Rec. loss: 0.4343 |  Task loss: 0.0763 | T: 284.81s
| It: 306001 | Rec. loss: 0.4308 |  Task loss: 0.0765 | T: 284.82s
| It: 307001 | Rec. loss: 0.4263 |  Task loss: 0.0765 | T: 261.47s
| It: 308001 | Rec. loss: 0.4223 |  Task loss: 0.0765 | T: 278.63s
| It: 309001 | Rec. loss: 0.4189 |  Task loss: 0.0766 | T: 262.73s
| It: 310001 | Rec. loss: 0.4155 |  Task loss: 0.0766 | T: 258.97s
| It: 311001 | Rec. loss: 0.4125 |  Task loss: 0.0766 | T: 258.99s
| It: 312001 | Rec. loss: 0.4099 |  Task loss: 0.0766 | T: 258.33s
| It: 313001 | Rec. loss: 0.4073 |  Task loss: 0.0766 | T: 258.17s
| It: 314001 | Rec. loss: 0.4052 |  Task loss: 0.0766 | T: 258.33s
| It: 315001 | Rec. loss: 0.4035 |  Task loss: 0.0767 | T: 259.18s
| It: 316001 | Rec. loss: 0.4020 |  Task loss: 0.0767 | T: 258.90s
| It: 317001 | Rec. loss: 0.4008 |  Task loss: 0.0767 | T: 292.20s
| It: 318001 | Rec. loss: 0.4001 |  Task loss: 0.0767 | T: 294.62s
| It: 319001 | Rec. loss: 0.3997 |  Task loss: 0.0767 | T: 298.29s
| It: 320000 | Rec. loss: 0.3996 |  Task loss: 0.0767 | T: 295.16s
Optimal candidate solution with rec. loss 1053.2302 selected.
Reconstruction stats:
Starting evaluations for attack effectiveness report...
The size of tensor a (55) must match the size of tensor b (61) at non-singleton dimension 3
None
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_post0_1.png
========================================================================

Trial 1

Investigating use case small_batch_imagenet with server type honest_but_curious.
Seed: 51829
Model architecture vggface2 loaded with 27,910,327 parameters and 29,712 buffers.
Overall this is a data ratio of      12:1 for target shape [16, 3, 224, 224] given that num_queries=1.
User (of type UserSingleStep) with settings:
    Number of data points: 16

    Threat model:
    User provides labels: False
    User provides buffers: True
    User provides number of data points: True

    Data:
    Dataset: flickr_faces
    user: 0
    
        
Server (of type HonestServer) with settings:
    Threat model: Honest-but-curious
    Number of planned queries: 1
    Has external/public data: False

    Model:
        model specification: vggface2
        model state: default
        public buffers: False

    Secrets: {}
    
Attacker (of type OptimizationBasedAttacker) with settings:
    Hyperparameter Template: see-through-gradients

    Objective: Euclidean loss with scale=0.0001 and task reg=0.0
    Regularizers: Total Variation, scale=0.0001. p=1 q=1. 
                  Input L^p norm regularization, scale=1e-06, p=2
                  Deep Inversion Regularization (matching batch norms), scale=0.1, first-bn-mult=10
    Augmentations: 

    Optimization Setup:
        optimizer: adam
        signed: False
        step_size: 0.1
        boxed: True
        max_iterations: 320000
        step_size_decay: cosine-decay
        langevin_noise: 0.01
        warmup: 100
        grad_clip: None
        callback: 1000
        
Computing user update on user 0 in model mode: training.
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_pre1.png
Reconstructing user data...
Files already downloaded and verified
initial data len: 16
Recovered labels [32, 75, 92, 290, 300, 382, 428, 437, 500, 506, 574, 602, 616, 772, 793, 870] through strategy yin.
| It: 1 | Rec. loss: 31.5120 |  Task loss: 10.6692 | T: 0.39s
| It: 1001 | Rec. loss: 10.6758 |  Task loss: 4.2633 | T: 293.22s
| It: 2001 | Rec. loss: 10.2943 |  Task loss: 2.9660 | T: 293.28s
| It: 3001 | Rec. loss: 10.0866 |  Task loss: 2.8430 | T: 293.90s
| It: 4001 | Rec. loss: 9.9487 |  Task loss: 2.2360 | T: 296.58s
| It: 5001 | Rec. loss: 9.9444 |  Task loss: 2.0942 | T: 299.07s
| It: 6001 | Rec. loss: 9.8917 |  Task loss: 2.0201 | T: 301.71s
| It: 7001 | Rec. loss: 9.8761 |  Task loss: 1.7116 | T: 304.23s
| It: 8001 | Rec. loss: 9.8600 |  Task loss: 1.5296 | T: 275.15s
| It: 9001 | Rec. loss: 9.8191 |  Task loss: 1.2092 | T: 259.36s
| It: 10001 | Rec. loss: 9.8045 |  Task loss: 1.0915 | T: 259.44s
| It: 11001 | Rec. loss: 9.7706 |  Task loss: 0.9646 | T: 259.51s
| It: 12001 | Rec. loss: 9.7652 |  Task loss: 0.9628 | T: 259.44s
| It: 13001 | Rec. loss: 9.7655 |  Task loss: 0.8810 | T: 259.50s
| It: 14001 | Rec. loss: 9.7507 |  Task loss: 0.6421 | T: 259.55s
| It: 15001 | Rec. loss: 9.7495 |  Task loss: 0.7098 | T: 257.12s
| It: 16001 | Rec. loss: 9.7427 |  Task loss: 0.6790 | T: 257.10s
| It: 17001 | Rec. loss: 9.7502 |  Task loss: 0.6460 | T: 259.32s
| It: 18001 | Rec. loss: 9.7228 |  Task loss: 0.6375 | T: 259.43s
| It: 19001 | Rec. loss: 9.6931 |  Task loss: 0.5196 | T: 259.34s
| It: 20001 | Rec. loss: 9.7102 |  Task loss: 0.6871 | T: 257.93s
| It: 21001 | Rec. loss: 9.6807 |  Task loss: 0.5990 | T: 258.30s
| It: 22001 | Rec. loss: 9.6546 |  Task loss: 0.6123 | T: 259.50s
| It: 23001 | Rec. loss: 9.6558 |  Task loss: 0.6364 | T: 259.33s
| It: 24001 | Rec. loss: 9.6543 |  Task loss: 0.5815 | T: 260.38s
| It: 25001 | Rec. loss: 9.6427 |  Task loss: 0.5664 | T: 260.72s
| It: 26001 | Rec. loss: 9.6444 |  Task loss: 0.4702 | T: 259.39s
| It: 27001 | Rec. loss: 9.6281 |  Task loss: 0.2644 | T: 259.76s
| It: 28001 | Rec. loss: 9.6057 |  Task loss: 0.2597 | T: 260.99s
| It: 29001 | Rec. loss: 9.6226 |  Task loss: 0.2449 | T: 260.81s
| It: 30001 | Rec. loss: 9.6308 |  Task loss: 0.2643 | T: 259.35s
| It: 31001 | Rec. loss: 9.5889 |  Task loss: 0.2610 | T: 259.10s
| It: 32001 | Rec. loss: 9.5853 |  Task loss: 0.2305 | T: 257.90s
| It: 33001 | Rec. loss: 9.5687 |  Task loss: 0.2387 | T: 257.94s
| It: 34001 | Rec. loss: 9.5592 |  Task loss: 0.2341 | T: 259.38s
| It: 35001 | Rec. loss: 9.5456 |  Task loss: 0.2406 | T: 260.27s
| It: 36001 | Rec. loss: 9.5330 |  Task loss: 0.2370 | T: 263.36s
| It: 37001 | Rec. loss: 9.5227 |  Task loss: 0.2308 | T: 258.79s
| It: 38001 | Rec. loss: 9.5078 |  Task loss: 0.2275 | T: 258.84s
| It: 39001 | Rec. loss: 9.5185 |  Task loss: 0.2233 | T: 259.26s
| It: 40001 | Rec. loss: 9.5029 |  Task loss: 0.2325 | T: 258.24s
| It: 41001 | Rec. loss: 9.4695 |  Task loss: 0.2351 | T: 258.89s
| It: 42001 | Rec. loss: 9.4662 |  Task loss: 0.2340 | T: 258.70s
| It: 43001 | Rec. loss: 9.4471 |  Task loss: 0.2291 | T: 257.15s
| It: 44001 | Rec. loss: 9.4875 |  Task loss: 0.2358 | T: 266.22s
| It: 45001 | Rec. loss: 9.4445 |  Task loss: 0.2411 | T: 272.66s
| It: 46001 | Rec. loss: 9.4321 |  Task loss: 0.2248 | T: 272.94s
| It: 47001 | Rec. loss: 9.4185 |  Task loss: 0.2241 | T: 272.21s
| It: 48001 | Rec. loss: 9.4082 |  Task loss: 0.2346 | T: 272.81s
| It: 49001 | Rec. loss: 9.4097 |  Task loss: 0.2463 | T: 270.11s
| It: 50001 | Rec. loss: 9.3764 |  Task loss: 0.2282 | T: 271.99s
| It: 51001 | Rec. loss: 9.3755 |  Task loss: 0.2347 | T: 272.87s
| It: 52001 | Rec. loss: 9.3867 |  Task loss: 0.2289 | T: 274.34s
| It: 53001 | Rec. loss: 9.3434 |  Task loss: 0.2342 | T: 273.49s
| It: 54001 | Rec. loss: 9.3114 |  Task loss: 0.2300 | T: 272.32s
| It: 55001 | Rec. loss: 9.3089 |  Task loss: 0.2311 | T: 273.79s
| It: 56001 | Rec. loss: 9.2970 |  Task loss: 0.2372 | T: 272.51s
| It: 57001 | Rec. loss: 9.2939 |  Task loss: 0.2373 | T: 271.99s
| It: 58001 | Rec. loss: 9.2979 |  Task loss: 0.2202 | T: 272.95s
| It: 59001 | Rec. loss: 9.2395 |  Task loss: 0.2219 | T: 271.88s
| It: 60001 | Rec. loss: 9.2518 |  Task loss: 0.2223 | T: 271.44s
| It: 61001 | Rec. loss: 9.2300 |  Task loss: 0.2374 | T: 272.05s
| It: 62001 | Rec. loss: 9.2090 |  Task loss: 0.2259 | T: 271.52s
| It: 63001 | Rec. loss: 9.2187 |  Task loss: 0.2278 | T: 269.15s
| It: 64001 | Rec. loss: 9.1862 |  Task loss: 0.2411 | T: 272.79s
| It: 65001 | Rec. loss: 9.1743 |  Task loss: 0.2279 | T: 272.38s
| It: 66001 | Rec. loss: 9.1660 |  Task loss: 0.2238 | T: 272.27s
| It: 67001 | Rec. loss: 9.1209 |  Task loss: 0.2311 | T: 270.71s
| It: 68001 | Rec. loss: 9.1367 |  Task loss: 0.2229 | T: 272.33s
| It: 69001 | Rec. loss: 9.0830 |  Task loss: 0.2220 | T: 273.20s
| It: 70001 | Rec. loss: 9.0793 |  Task loss: 0.2233 | T: 273.17s
| It: 71001 | Rec. loss: 9.0455 |  Task loss: 0.2321 | T: 271.56s
| It: 72001 | Rec. loss: 9.0171 |  Task loss: 0.2237 | T: 272.07s
| It: 73001 | Rec. loss: 9.0086 |  Task loss: 0.2284 | T: 272.21s
| It: 74001 | Rec. loss: 8.9695 |  Task loss: 0.2189 | T: 269.86s
| It: 75001 | Rec. loss: 8.9654 |  Task loss: 0.2291 | T: 273.45s
| It: 76001 | Rec. loss: 8.9720 |  Task loss: 0.2257 | T: 271.05s
| It: 77001 | Rec. loss: 8.9518 |  Task loss: 0.2326 | T: 271.75s
| It: 78001 | Rec. loss: 8.9203 |  Task loss: 0.2279 | T: 271.83s
| It: 79001 | Rec. loss: 8.9358 |  Task loss: 0.2292 | T: 271.80s
| It: 80001 | Rec. loss: 8.8776 |  Task loss: 0.2266 | T: 271.40s
| It: 81001 | Rec. loss: 8.8715 |  Task loss: 0.2207 | T: 272.36s
| It: 82001 | Rec. loss: 8.8570 |  Task loss: 0.2192 | T: 273.50s
| It: 83001 | Rec. loss: 8.8232 |  Task loss: 0.2258 | T: 273.40s
| It: 84001 | Rec. loss: 8.8170 |  Task loss: 0.2082 | T: 272.10s
| It: 85001 | Rec. loss: 8.7814 |  Task loss: 0.2169 | T: 272.39s
| It: 86001 | Rec. loss: 8.7761 |  Task loss: 0.2213 | T: 283.61s
| It: 87001 | Rec. loss: 8.7543 |  Task loss: 0.2327 | T: 288.72s
| It: 88001 | Rec. loss: 8.7196 |  Task loss: 0.2144 | T: 273.73s
| It: 89001 | Rec. loss: 8.6912 |  Task loss: 0.2170 | T: 271.46s
| It: 90001 | Rec. loss: 8.6671 |  Task loss: 0.2233 | T: 273.54s
| It: 91001 | Rec. loss: 8.6510 |  Task loss: 0.2208 | T: 271.08s
| It: 92001 | Rec. loss: 8.6192 |  Task loss: 0.2098 | T: 271.66s
| It: 93001 | Rec. loss: 8.6031 |  Task loss: 0.2044 | T: 273.04s
| It: 94001 | Rec. loss: 8.6015 |  Task loss: 0.2059 | T: 273.20s
| It: 95001 | Rec. loss: 8.5477 |  Task loss: 0.2050 | T: 272.83s
| It: 96001 | Rec. loss: 8.5368 |  Task loss: 0.2099 | T: 271.09s
| It: 97001 | Rec. loss: 8.4995 |  Task loss: 0.2017 | T: 272.13s
| It: 98001 | Rec. loss: 8.4656 |  Task loss: 0.2180 | T: 272.49s
| It: 99001 | Rec. loss: 8.4877 |  Task loss: 0.2117 | T: 273.82s
| It: 100001 | Rec. loss: 8.4101 |  Task loss: 0.2067 | T: 272.90s
| It: 101001 | Rec. loss: 8.4347 |  Task loss: 0.2003 | T: 272.57s
| It: 102001 | Rec. loss: 8.3590 |  Task loss: 0.2006 | T: 272.58s
| It: 103001 | Rec. loss: 8.3471 |  Task loss: 0.2083 | T: 272.60s
| It: 104001 | Rec. loss: 8.3106 |  Task loss: 0.1916 | T: 272.37s
| It: 105001 | Rec. loss: 8.2888 |  Task loss: 0.2091 | T: 273.08s
| It: 106001 | Rec. loss: 8.2599 |  Task loss: 0.1882 | T: 270.42s
| It: 107001 | Rec. loss: 8.2365 |  Task loss: 0.2005 | T: 271.75s
| It: 108001 | Rec. loss: 8.2080 |  Task loss: 0.2061 | T: 272.59s
| It: 109001 | Rec. loss: 8.1799 |  Task loss: 0.2043 | T: 271.78s
| It: 110001 | Rec. loss: 8.1455 |  Task loss: 0.1971 | T: 271.12s
| It: 111001 | Rec. loss: 8.1164 |  Task loss: 0.1950 | T: 273.99s
| It: 112001 | Rec. loss: 8.0768 |  Task loss: 0.2050 | T: 271.48s
| It: 113001 | Rec. loss: 8.0817 |  Task loss: 0.1993 | T: 271.70s
| It: 114001 | Rec. loss: 8.0392 |  Task loss: 0.2024 | T: 271.91s
| It: 115001 | Rec. loss: 7.9857 |  Task loss: 0.2163 | T: 271.05s
| It: 116001 | Rec. loss: 7.9806 |  Task loss: 0.2031 | T: 272.93s
| It: 117001 | Rec. loss: 7.9117 |  Task loss: 0.1938 | T: 273.55s
| It: 118001 | Rec. loss: 7.9036 |  Task loss: 0.1933 | T: 273.01s
| It: 119001 | Rec. loss: 7.8505 |  Task loss: 0.1843 | T: 273.46s
| It: 120001 | Rec. loss: 7.8617 |  Task loss: 0.1924 | T: 272.73s
| It: 121001 | Rec. loss: 7.7949 |  Task loss: 0.1841 | T: 272.64s
| It: 122001 | Rec. loss: 7.7702 |  Task loss: 0.1935 | T: 272.85s
| It: 123001 | Rec. loss: 7.7146 |  Task loss: 0.1992 | T: 272.09s
| It: 124001 | Rec. loss: 7.6998 |  Task loss: 0.1886 | T: 272.60s
| It: 125001 | Rec. loss: 7.6621 |  Task loss: 0.1943 | T: 271.56s
| It: 126001 | Rec. loss: 7.6560 |  Task loss: 0.1851 | T: 272.36s
| It: 127001 | Rec. loss: 7.5968 |  Task loss: 0.1955 | T: 287.75s
| It: 128001 | Rec. loss: 7.5581 |  Task loss: 0.1939 | T: 281.89s
| It: 129001 | Rec. loss: 7.5337 |  Task loss: 0.1998 | T: 271.48s
| It: 130001 | Rec. loss: 7.4759 |  Task loss: 0.1922 | T: 273.75s
| It: 131001 | Rec. loss: 7.4418 |  Task loss: 0.1961 | T: 270.65s
| It: 132001 | Rec. loss: 7.4061 |  Task loss: 0.1942 | T: 272.91s
| It: 133001 | Rec. loss: 7.3728 |  Task loss: 0.1836 | T: 273.48s
| It: 134001 | Rec. loss: 7.3558 |  Task loss: 0.1860 | T: 272.54s
| It: 135001 | Rec. loss: 7.2843 |  Task loss: 0.1799 | T: 272.94s
| It: 136001 | Rec. loss: 7.2431 |  Task loss: 0.1970 | T: 271.75s
| It: 137001 | Rec. loss: 7.2151 |  Task loss: 0.1917 | T: 271.70s
| It: 138001 | Rec. loss: 7.1585 |  Task loss: 0.1885 | T: 271.62s
| It: 139001 | Rec. loss: 7.1495 |  Task loss: 0.1801 | T: 272.65s
| It: 140001 | Rec. loss: 7.0743 |  Task loss: 0.1793 | T: 271.31s
| It: 141001 | Rec. loss: 7.0408 |  Task loss: 0.1772 | T: 269.34s
| It: 142001 | Rec. loss: 6.9908 |  Task loss: 0.1899 | T: 272.07s
| It: 143001 | Rec. loss: 6.9747 |  Task loss: 0.1754 | T: 272.76s
| It: 144001 | Rec. loss: 6.9165 |  Task loss: 0.1672 | T: 273.58s
| It: 145001 | Rec. loss: 6.8694 |  Task loss: 0.1758 | T: 272.02s
| It: 146001 | Rec. loss: 6.8153 |  Task loss: 0.1770 | T: 273.00s
| It: 147001 | Rec. loss: 6.7703 |  Task loss: 0.1746 | T: 271.56s
| It: 148001 | Rec. loss: 6.7301 |  Task loss: 0.1660 | T: 270.98s
| It: 149001 | Rec. loss: 6.6625 |  Task loss: 0.1701 | T: 271.81s
| It: 150001 | Rec. loss: 6.6278 |  Task loss: 0.1746 | T: 272.77s
| It: 151001 | Rec. loss: 6.5973 |  Task loss: 0.1773 | T: 270.32s
| It: 152001 | Rec. loss: 6.5571 |  Task loss: 0.1647 | T: 273.57s
| It: 153001 | Rec. loss: 6.4839 |  Task loss: 0.1640 | T: 271.29s
| It: 154001 | Rec. loss: 6.4581 |  Task loss: 0.1732 | T: 273.16s
| It: 155001 | Rec. loss: 6.3959 |  Task loss: 0.1733 | T: 271.63s
| It: 156001 | Rec. loss: 6.3330 |  Task loss: 0.1703 | T: 271.80s
| It: 157001 | Rec. loss: 6.2867 |  Task loss: 0.1630 | T: 272.41s
| It: 158001 | Rec. loss: 6.2448 |  Task loss: 0.1677 | T: 270.95s
| It: 159001 | Rec. loss: 6.1849 |  Task loss: 0.1639 | T: 272.71s
| It: 160001 | Rec. loss: 6.1360 |  Task loss: 0.1629 | T: 272.88s
| It: 161001 | Rec. loss: 6.0881 |  Task loss: 0.1622 | T: 272.27s
| It: 162001 | Rec. loss: 6.0203 |  Task loss: 0.1664 | T: 273.70s
| It: 163001 | Rec. loss: 5.9855 |  Task loss: 0.1592 | T: 272.20s
| It: 164001 | Rec. loss: 5.9039 |  Task loss: 0.1608 | T: 272.19s
| It: 165001 | Rec. loss: 5.8686 |  Task loss: 0.1637 | T: 271.31s
| It: 166001 | Rec. loss: 5.8070 |  Task loss: 0.1549 | T: 273.47s
| It: 167001 | Rec. loss: 5.7511 |  Task loss: 0.1604 | T: 271.38s
| It: 168001 | Rec. loss: 5.6974 |  Task loss: 0.1523 | T: 287.11s
| It: 169001 | Rec. loss: 5.6334 |  Task loss: 0.1571 | T: 284.01s
| It: 170001 | Rec. loss: 5.5691 |  Task loss: 0.1570 | T: 271.38s
| It: 171001 | Rec. loss: 5.5152 |  Task loss: 0.1521 | T: 272.28s
| It: 172001 | Rec. loss: 5.4574 |  Task loss: 0.1483 | T: 270.87s
| It: 173001 | Rec. loss: 5.4114 |  Task loss: 0.1521 | T: 271.96s
| It: 174001 | Rec. loss: 5.3461 |  Task loss: 0.1473 | T: 271.76s
| It: 175001 | Rec. loss: 5.2863 |  Task loss: 0.1564 | T: 271.36s
| It: 176001 | Rec. loss: 5.2428 |  Task loss: 0.1482 | T: 273.39s
| It: 177001 | Rec. loss: 5.1703 |  Task loss: 0.1430 | T: 272.50s
| It: 178001 | Rec. loss: 5.0972 |  Task loss: 0.1413 | T: 272.69s
| It: 179001 | Rec. loss: 5.0610 |  Task loss: 0.1397 | T: 270.78s
| It: 180001 | Rec. loss: 4.9980 |  Task loss: 0.1449 | T: 272.33s
| It: 181001 | Rec. loss: 4.9406 |  Task loss: 0.1498 | T: 272.91s
| It: 182001 | Rec. loss: 4.8711 |  Task loss: 0.1378 | T: 272.87s
| It: 183001 | Rec. loss: 4.7886 |  Task loss: 0.1399 | T: 271.52s
| It: 184001 | Rec. loss: 4.7416 |  Task loss: 0.1372 | T: 272.27s
| It: 185001 | Rec. loss: 4.6965 |  Task loss: 0.1349 | T: 272.06s
| It: 186001 | Rec. loss: 4.6050 |  Task loss: 0.1378 | T: 272.07s
| It: 187001 | Rec. loss: 4.5508 |  Task loss: 0.1377 | T: 271.02s
| It: 188001 | Rec. loss: 4.4908 |  Task loss: 0.1366 | T: 272.51s
| It: 189001 | Rec. loss: 4.4137 |  Task loss: 0.1398 | T: 271.38s
| It: 190001 | Rec. loss: 4.3699 |  Task loss: 0.1392 | T: 273.11s
| It: 191001 | Rec. loss: 4.2851 |  Task loss: 0.1414 | T: 273.30s
| It: 192001 | Rec. loss: 4.2213 |  Task loss: 0.1388 | T: 272.42s
| It: 193001 | Rec. loss: 4.1670 |  Task loss: 0.1362 | T: 272.56s
| It: 194001 | Rec. loss: 4.1098 |  Task loss: 0.1377 | T: 272.28s
| It: 195001 | Rec. loss: 4.0313 |  Task loss: 0.1345 | T: 272.69s
| It: 196001 | Rec. loss: 3.9907 |  Task loss: 0.1367 | T: 272.08s
| It: 197001 | Rec. loss: 3.9003 |  Task loss: 0.1338 | T: 272.46s
| It: 198001 | Rec. loss: 3.8775 |  Task loss: 0.1327 | T: 272.83s
| It: 199001 | Rec. loss: 3.8027 |  Task loss: 0.1352 | T: 273.12s
| It: 200001 | Rec. loss: 3.7193 |  Task loss: 0.1343 | T: 271.93s
| It: 201001 | Rec. loss: 3.6679 |  Task loss: 0.1324 | T: 272.17s
| It: 202001 | Rec. loss: 3.6019 |  Task loss: 0.1308 | T: 272.00s
| It: 203001 | Rec. loss: 3.5337 |  Task loss: 0.1343 | T: 273.32s
| It: 204001 | Rec. loss: 3.4794 |  Task loss: 0.1286 | T: 270.36s
| It: 205001 | Rec. loss: 3.4346 |  Task loss: 0.1262 | T: 273.08s
| It: 206001 | Rec. loss: 3.3633 |  Task loss: 0.1305 | T: 273.10s
| It: 207001 | Rec. loss: 3.3045 |  Task loss: 0.1260 | T: 271.79s
| It: 208001 | Rec. loss: 3.2557 |  Task loss: 0.1297 | T: 271.22s
| It: 209001 | Rec. loss: 3.1885 |  Task loss: 0.1300 | T: 287.08s
| It: 210001 | Rec. loss: 3.1362 |  Task loss: 0.1253 | T: 283.78s
| It: 211001 | Rec. loss: 3.0818 |  Task loss: 0.1256 | T: 272.03s
| It: 212001 | Rec. loss: 3.0257 |  Task loss: 0.1252 | T: 271.32s
| It: 213001 | Rec. loss: 2.9869 |  Task loss: 0.1269 | T: 272.49s
| It: 214001 | Rec. loss: 2.9260 |  Task loss: 0.1250 | T: 270.28s
| It: 215001 | Rec. loss: 2.8660 |  Task loss: 0.1236 | T: 273.32s
| It: 216001 | Rec. loss: 2.8296 |  Task loss: 0.1242 | T: 273.51s
| It: 217001 | Rec. loss: 2.7689 |  Task loss: 0.1225 | T: 273.31s
| It: 218001 | Rec. loss: 2.7210 |  Task loss: 0.1235 | T: 272.33s
| It: 219001 | Rec. loss: 2.6841 |  Task loss: 0.1195 | T: 273.50s
| It: 220001 | Rec. loss: 2.6269 |  Task loss: 0.1180 | T: 272.29s
| It: 221001 | Rec. loss: 2.5822 |  Task loss: 0.1201 | T: 272.39s
| It: 222001 | Rec. loss: 2.5421 |  Task loss: 0.1195 | T: 271.67s
| It: 223001 | Rec. loss: 2.4867 |  Task loss: 0.1156 | T: 270.95s
| It: 224001 | Rec. loss: 2.4358 |  Task loss: 0.1145 | T: 272.74s
| It: 225001 | Rec. loss: 2.3969 |  Task loss: 0.1148 | T: 272.36s
| It: 226001 | Rec. loss: 2.3519 |  Task loss: 0.1123 | T: 271.57s
| It: 227001 | Rec. loss: 2.3071 |  Task loss: 0.1145 | T: 272.47s
| It: 228001 | Rec. loss: 2.2591 |  Task loss: 0.1139 | T: 271.83s
| It: 229001 | Rec. loss: 2.2186 |  Task loss: 0.1136 | T: 273.10s
| It: 230001 | Rec. loss: 2.1791 |  Task loss: 0.1093 | T: 273.29s
| It: 231001 | Rec. loss: 2.1381 |  Task loss: 0.1121 | T: 272.50s
| It: 232001 | Rec. loss: 2.0978 |  Task loss: 0.1109 | T: 273.38s
| It: 233001 | Rec. loss: 2.0570 |  Task loss: 0.1089 | T: 273.24s
| It: 234001 | Rec. loss: 2.0214 |  Task loss: 0.1091 | T: 269.74s
| It: 235001 | Rec. loss: 1.9857 |  Task loss: 0.1066 | T: 271.91s
| It: 236001 | Rec. loss: 1.9432 |  Task loss: 0.1104 | T: 273.57s
| It: 237001 | Rec. loss: 1.9035 |  Task loss: 0.1076 | T: 272.18s
| It: 238001 | Rec. loss: 1.8695 |  Task loss: 0.1077 | T: 273.34s
| It: 239001 | Rec. loss: 1.8322 |  Task loss: 0.1078 | T: 271.44s
| It: 240001 | Rec. loss: 1.7991 |  Task loss: 0.1081 | T: 272.05s
| It: 241001 | Rec. loss: 1.7614 |  Task loss: 0.1049 | T: 272.56s
| It: 242001 | Rec. loss: 1.7222 |  Task loss: 0.1044 | T: 272.28s
| It: 243001 | Rec. loss: 1.6906 |  Task loss: 0.1042 | T: 270.43s
| It: 244001 | Rec. loss: 1.6606 |  Task loss: 0.1023 | T: 273.47s
| It: 245001 | Rec. loss: 1.6273 |  Task loss: 0.1000 | T: 273.41s
| It: 246001 | Rec. loss: 1.5959 |  Task loss: 0.1027 | T: 271.84s
| It: 247001 | Rec. loss: 1.5643 |  Task loss: 0.1012 | T: 273.29s
| It: 248001 | Rec. loss: 1.5332 |  Task loss: 0.1015 | T: 273.24s
| It: 249001 | Rec. loss: 1.5088 |  Task loss: 0.1012 | T: 273.18s
| It: 250001 | Rec. loss: 1.4769 |  Task loss: 0.1008 | T: 292.33s
| It: 251001 | Rec. loss: 1.4517 |  Task loss: 0.1010 | T: 270.40s
| It: 252001 | Rec. loss: 1.4194 |  Task loss: 0.1006 | T: 272.57s
| It: 253001 | Rec. loss: 1.3913 |  Task loss: 0.0995 | T: 272.71s
| It: 254001 | Rec. loss: 1.3642 |  Task loss: 0.0981 | T: 273.02s
| It: 255001 | Rec. loss: 1.3368 |  Task loss: 0.0980 | T: 270.68s
| It: 256001 | Rec. loss: 1.3120 |  Task loss: 0.0965 | T: 272.54s
| It: 257001 | Rec. loss: 1.2859 |  Task loss: 0.0976 | T: 271.79s
| It: 258001 | Rec. loss: 1.2650 |  Task loss: 0.0958 | T: 272.30s
| It: 259001 | Rec. loss: 1.2380 |  Task loss: 0.0967 | T: 273.17s
| It: 260001 | Rec. loss: 1.2217 |  Task loss: 0.0956 | T: 270.95s
| It: 261001 | Rec. loss: 1.1920 |  Task loss: 0.0957 | T: 272.75s
| It: 262001 | Rec. loss: 1.1787 |  Task loss: 0.0944 | T: 268.83s
| It: 263001 | Rec. loss: 1.1498 |  Task loss: 0.0938 | T: 272.08s
| It: 264001 | Rec. loss: 1.1287 |  Task loss: 0.0940 | T: 272.63s
| It: 265001 | Rec. loss: 1.1054 |  Task loss: 0.0936 | T: 272.69s
| It: 266001 | Rec. loss: 1.0845 |  Task loss: 0.0932 | T: 272.63s
| It: 267001 | Rec. loss: 1.0614 |  Task loss: 0.0943 | T: 270.53s
| It: 268001 | Rec. loss: 1.0409 |  Task loss: 0.0930 | T: 271.57s
| It: 269001 | Rec. loss: 1.0226 |  Task loss: 0.0924 | T: 272.78s
| It: 270001 | Rec. loss: 1.0054 |  Task loss: 0.0919 | T: 270.67s
| It: 271001 | Rec. loss: 0.9858 |  Task loss: 0.0914 | T: 272.26s
| It: 272001 | Rec. loss: 0.9637 |  Task loss: 0.0904 | T: 271.76s
| It: 273001 | Rec. loss: 0.9488 |  Task loss: 0.0907 | T: 272.65s
| It: 274001 | Rec. loss: 0.9287 |  Task loss: 0.0904 | T: 272.35s
| It: 275001 | Rec. loss: 0.9100 |  Task loss: 0.0902 | T: 272.38s
| It: 276001 | Rec. loss: 0.8921 |  Task loss: 0.0893 | T: 270.76s
| It: 277001 | Rec. loss: 0.8759 |  Task loss: 0.0894 | T: 273.85s
| It: 278001 | Rec. loss: 0.8590 |  Task loss: 0.0897 | T: 271.42s
| It: 279001 | Rec. loss: 0.8452 |  Task loss: 0.0893 | T: 272.03s
| It: 280001 | Rec. loss: 0.8276 |  Task loss: 0.0891 | T: 272.81s
| It: 281001 | Rec. loss: 0.8081 |  Task loss: 0.0884 | T: 272.47s
| It: 282001 | Rec. loss: 0.7932 |  Task loss: 0.0886 | T: 272.33s
| It: 283001 | Rec. loss: 0.7764 |  Task loss: 0.0882 | T: 274.24s
| It: 284001 | Rec. loss: 0.7637 |  Task loss: 0.0881 | T: 272.12s
| It: 285001 | Rec. loss: 0.7471 |  Task loss: 0.0876 | T: 272.05s
| It: 286001 | Rec. loss: 0.7337 |  Task loss: 0.0876 | T: 273.11s
| It: 287001 | Rec. loss: 0.7189 |  Task loss: 0.0874 | T: 271.90s
| It: 288001 | Rec. loss: 0.7053 |  Task loss: 0.0872 | T: 272.39s
| It: 289001 | Rec. loss: 0.6934 |  Task loss: 0.0872 | T: 273.30s
| It: 290001 | Rec. loss: 0.6800 |  Task loss: 0.0869 | T: 271.59s
| It: 291001 | Rec. loss: 0.6692 |  Task loss: 0.0867 | T: 295.68s
| It: 292001 | Rec. loss: 0.6566 |  Task loss: 0.0867 | T: 275.57s
| It: 293001 | Rec. loss: 0.6454 |  Task loss: 0.0865 | T: 271.20s
| It: 294001 | Rec. loss: 0.6346 |  Task loss: 0.0863 | T: 273.02s
| It: 295001 | Rec. loss: 0.6239 |  Task loss: 0.0865 | T: 271.71s
| It: 296001 | Rec. loss: 0.6139 |  Task loss: 0.0865 | T: 272.16s
| It: 297001 | Rec. loss: 0.6040 |  Task loss: 0.0865 | T: 273.82s
| It: 298001 | Rec. loss: 0.5952 |  Task loss: 0.0866 | T: 272.86s
| It: 299001 | Rec. loss: 0.5866 |  Task loss: 0.0866 | T: 272.46s
| It: 300001 | Rec. loss: 0.5786 |  Task loss: 0.0867 | T: 271.63s
| It: 301001 | Rec. loss: 0.5706 |  Task loss: 0.0866 | T: 271.96s
| It: 302001 | Rec. loss: 0.5633 |  Task loss: 0.0867 | T: 272.71s
| It: 303001 | Rec. loss: 0.5556 |  Task loss: 0.0868 | T: 271.87s
| It: 304001 | Rec. loss: 0.5488 |  Task loss: 0.0868 | T: 271.07s
| It: 305001 | Rec. loss: 0.5428 |  Task loss: 0.0869 | T: 271.10s
| It: 306001 | Rec. loss: 0.5358 |  Task loss: 0.0870 | T: 272.68s
| It: 307001 | Rec. loss: 0.5299 |  Task loss: 0.0870 | T: 272.59s
| It: 308001 | Rec. loss: 0.5244 |  Task loss: 0.0870 | T: 272.94s
| It: 309001 | Rec. loss: 0.5194 |  Task loss: 0.0870 | T: 272.43s
| It: 310001 | Rec. loss: 0.5146 |  Task loss: 0.0870 | T: 273.30s
| It: 311001 | Rec. loss: 0.5102 |  Task loss: 0.0869 | T: 273.09s
| It: 312001 | Rec. loss: 0.5061 |  Task loss: 0.0869 | T: 273.00s
| It: 313001 | Rec. loss: 0.5023 |  Task loss: 0.0869 | T: 273.52s
| It: 314001 | Rec. loss: 0.4990 |  Task loss: 0.0869 | T: 274.00s
| It: 315001 | Rec. loss: 0.4961 |  Task loss: 0.0869 | T: 273.37s
| It: 316001 | Rec. loss: 0.4938 |  Task loss: 0.0869 | T: 272.53s
| It: 317001 | Rec. loss: 0.4920 |  Task loss: 0.0868 | T: 271.66s
| It: 318001 | Rec. loss: 0.4908 |  Task loss: 0.0868 | T: 271.70s
| It: 319001 | Rec. loss: 0.4903 |  Task loss: 0.0868 | T: 272.45s
| It: 320000 | Rec. loss: 0.4902 |  Task loss: 0.0868 | T: 273.11s
Optimal candidate solution with rec. loss 966.5209 selected.
Reconstruction stats:
Starting evaluations for attack effectiveness report...
The size of tensor a (55) must match the size of tensor b (61) at non-singleton dimension 3
None
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_post1_1.png
========================================================================

Trial 2

Investigating use case small_batch_imagenet with server type honest_but_curious.
Seed: 88110
Model architecture vggface2 loaded with 27,910,327 parameters and 29,712 buffers.
Overall this is a data ratio of      12:1 for target shape [16, 3, 224, 224] given that num_queries=1.
User (of type UserSingleStep) with settings:
    Number of data points: 16

    Threat model:
    User provides labels: False
    User provides buffers: True
    User provides number of data points: True

    Data:
    Dataset: flickr_faces
    user: 0
    
        
Server (of type HonestServer) with settings:
    Threat model: Honest-but-curious
    Number of planned queries: 1
    Has external/public data: False

    Model:
        model specification: vggface2
        model state: default
        public buffers: False

    Secrets: {}
    
Attacker (of type OptimizationBasedAttacker) with settings:
    Hyperparameter Template: see-through-gradients

    Objective: Euclidean loss with scale=0.0001 and task reg=0.0
    Regularizers: Total Variation, scale=0.0001. p=1 q=1. 
                  Input L^p norm regularization, scale=1e-06, p=2
                  Deep Inversion Regularization (matching batch norms), scale=0.1, first-bn-mult=10
    Augmentations: 

    Optimization Setup:
        optimizer: adam
        signed: False
        step_size: 0.1
        boxed: True
        max_iterations: 320000
        step_size_decay: cosine-decay
        langevin_noise: 0.01
        warmup: 100
        grad_clip: None
        callback: 1000
        
Computing user update on user 0 in model mode: training.
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_pre2.png
Reconstructing user data...
Files already downloaded and verified
initial data len: 16
Recovered labels [12, 30, 220, 223, 467, 483, 590, 596, 679, 699, 715, 716, 725, 776, 918, 971] through strategy yin.
| It: 1 | Rec. loss: 31.7354 |  Task loss: 11.3083 | T: 0.27s
| It: 1001 | Rec. loss: 10.8701 |  Task loss: 3.0763 | T: 273.74s
| It: 2001 | Rec. loss: 10.5983 |  Task loss: 2.5301 | T: 274.66s
| It: 3001 | Rec. loss: 10.5016 |  Task loss: 2.5053 | T: 272.70s
| It: 4001 | Rec. loss: 10.4629 |  Task loss: 2.3389 | T: 273.77s
| It: 5001 | Rec. loss: 10.4417 |  Task loss: 2.2920 | T: 273.20s
| It: 6001 | Rec. loss: 10.4140 |  Task loss: 1.9424 | T: 273.13s
| It: 7001 | Rec. loss: 10.3838 |  Task loss: 1.6998 | T: 271.24s
| It: 8001 | Rec. loss: 10.3794 |  Task loss: 1.5625 | T: 274.57s
| It: 9001 | Rec. loss: 10.3643 |  Task loss: 1.6083 | T: 274.04s
| It: 10001 | Rec. loss: 10.3603 |  Task loss: 1.5059 | T: 273.15s
| It: 11001 | Rec. loss: 10.3476 |  Task loss: 1.4000 | T: 274.49s
| It: 12001 | Rec. loss: 10.3211 |  Task loss: 1.4077 | T: 300.41s
| It: 13001 | Rec. loss: 10.3075 |  Task loss: 1.3959 | T: 273.62s
| It: 14001 | Rec. loss: 10.3178 |  Task loss: 1.3473 | T: 273.15s
| It: 15001 | Rec. loss: 10.2994 |  Task loss: 1.3007 | T: 272.95s
| It: 16001 | Rec. loss: 10.2869 |  Task loss: 1.3063 | T: 272.23s
| It: 17001 | Rec. loss: 10.2768 |  Task loss: 1.3265 | T: 272.44s
| It: 18001 | Rec. loss: 10.3089 |  Task loss: 1.2750 | T: 272.36s
| It: 19001 | Rec. loss: 10.2859 |  Task loss: 1.1447 | T: 272.93s
| It: 20001 | Rec. loss: 10.2578 |  Task loss: 1.1636 | T: 272.93s
| It: 21001 | Rec. loss: 10.2606 |  Task loss: 1.0842 | T: 274.48s
| It: 22001 | Rec. loss: 10.2972 |  Task loss: 1.1249 | T: 273.53s
| It: 23001 | Rec. loss: 10.2193 |  Task loss: 1.0943 | T: 272.63s
| It: 24001 | Rec. loss: 10.2114 |  Task loss: 1.1367 | T: 274.57s
| It: 25001 | Rec. loss: 10.2052 |  Task loss: 1.1068 | T: 274.13s
| It: 26001 | Rec. loss: 10.1930 |  Task loss: 1.0928 | T: 272.78s
| It: 27001 | Rec. loss: 10.1829 |  Task loss: 1.1175 | T: 272.06s
| It: 28001 | Rec. loss: 10.1907 |  Task loss: 0.9847 | T: 272.00s
| It: 29001 | Rec. loss: 10.1748 |  Task loss: 0.9908 | T: 274.13s
| It: 30001 | Rec. loss: 10.1715 |  Task loss: 1.0604 | T: 272.97s
| It: 31001 | Rec. loss: 10.1624 |  Task loss: 1.1544 | T: 272.35s
| It: 32001 | Rec. loss: 10.1344 |  Task loss: 1.0295 | T: 270.76s
| It: 33001 | Rec. loss: 10.1301 |  Task loss: 1.0046 | T: 273.14s
| It: 34001 | Rec. loss: 10.1629 |  Task loss: 1.0169 | T: 273.22s
| It: 35001 | Rec. loss: 10.0978 |  Task loss: 1.0573 | T: 272.96s
| It: 36001 | Rec. loss: 10.1504 |  Task loss: 1.0660 | T: 272.33s
| It: 37001 | Rec. loss: 10.1149 |  Task loss: 1.0350 | T: 271.95s
| It: 38001 | Rec. loss: 10.0756 |  Task loss: 1.0108 | T: 273.89s
| It: 39001 | Rec. loss: 10.0702 |  Task loss: 1.1005 | T: 272.98s
| It: 40001 | Rec. loss: 10.0617 |  Task loss: 1.0797 | T: 272.61s
| It: 41001 | Rec. loss: 10.0374 |  Task loss: 1.0245 | T: 272.40s
| It: 42001 | Rec. loss: 10.0349 |  Task loss: 1.0431 | T: 272.89s
| It: 43001 | Rec. loss: 10.0275 |  Task loss: 1.0090 | T: 272.75s
| It: 44001 | Rec. loss: 9.9997 |  Task loss: 1.1094 | T: 271.40s
| It: 45001 | Rec. loss: 9.9783 |  Task loss: 1.1445 | T: 271.64s
| It: 46001 | Rec. loss: 9.9743 |  Task loss: 1.1676 | T: 272.60s
| It: 47001 | Rec. loss: 9.9500 |  Task loss: 1.1149 | T: 271.88s
| It: 48001 | Rec. loss: 9.9334 |  Task loss: 0.9849 | T: 273.38s
| It: 49001 | Rec. loss: 9.9316 |  Task loss: 1.0252 | T: 272.95s
| It: 50001 | Rec. loss: 9.9292 |  Task loss: 0.9446 | T: 271.98s
| It: 51001 | Rec. loss: 9.9128 |  Task loss: 0.9149 | T: 273.37s
| It: 52001 | Rec. loss: 9.9197 |  Task loss: 0.8518 | T: 273.25s
| It: 53001 | Rec. loss: 9.9031 |  Task loss: 0.8370 | T: 298.26s
| It: 54001 | Rec. loss: 9.8612 |  Task loss: 0.9538 | T: 272.87s
| It: 55001 | Rec. loss: 9.8641 |  Task loss: 0.8835 | T: 272.51s
| It: 56001 | Rec. loss: 9.8418 |  Task loss: 0.9953 | T: 273.33s
| It: 57001 | Rec. loss: 9.8540 |  Task loss: 0.9463 | T: 271.61s
| It: 58001 | Rec. loss: 9.8241 |  Task loss: 0.9490 | T: 272.85s
| It: 59001 | Rec. loss: 9.7754 |  Task loss: 0.8893 | T: 273.62s
| It: 60001 | Rec. loss: 9.7580 |  Task loss: 0.8494 | T: 273.32s
| It: 61001 | Rec. loss: 9.8057 |  Task loss: 0.8308 | T: 272.39s
| It: 62001 | Rec. loss: 9.7449 |  Task loss: 0.7536 | T: 272.25s
| It: 63001 | Rec. loss: 9.7398 |  Task loss: 0.8579 | T: 273.95s
| It: 64001 | Rec. loss: 9.7133 |  Task loss: 0.8084 | T: 271.16s
| It: 65001 | Rec. loss: 9.6845 |  Task loss: 0.7549 | T: 272.35s
| It: 66001 | Rec. loss: 9.6750 |  Task loss: 0.6048 | T: 272.79s
| It: 67001 | Rec. loss: 9.6353 |  Task loss: 0.2373 | T: 273.47s
| It: 68001 | Rec. loss: 9.6475 |  Task loss: 0.2278 | T: 272.33s
| It: 69001 | Rec. loss: 9.6052 |  Task loss: 0.2058 | T: 271.78s
| It: 70001 | Rec. loss: 9.5723 |  Task loss: 0.2059 | T: 273.24s
| It: 71001 | Rec. loss: 9.5624 |  Task loss: 0.2072 | T: 272.62s
| It: 72001 | Rec. loss: 9.5533 |  Task loss: 0.2057 | T: 272.38s
| It: 73001 | Rec. loss: 9.5371 |  Task loss: 0.2020 | T: 271.17s
| It: 74001 | Rec. loss: 9.4965 |  Task loss: 0.1951 | T: 271.93s
| It: 75001 | Rec. loss: 9.5016 |  Task loss: 0.2103 | T: 272.10s
| It: 76001 | Rec. loss: 9.4609 |  Task loss: 0.1964 | T: 273.27s
| It: 77001 | Rec. loss: 9.4429 |  Task loss: 0.1914 | T: 271.15s
| It: 78001 | Rec. loss: 9.4183 |  Task loss: 0.2079 | T: 272.21s
| It: 79001 | Rec. loss: 9.3900 |  Task loss: 0.2105 | T: 271.83s
| It: 80001 | Rec. loss: 9.3719 |  Task loss: 0.1960 | T: 272.29s
| It: 81001 | Rec. loss: 9.3677 |  Task loss: 0.2088 | T: 273.54s
| It: 82001 | Rec. loss: 9.3285 |  Task loss: 0.2067 | T: 272.96s
| It: 83001 | Rec. loss: 9.2940 |  Task loss: 0.2100 | T: 273.22s
| It: 84001 | Rec. loss: 9.2747 |  Task loss: 0.2061 | T: 271.77s
| It: 85001 | Rec. loss: 9.2589 |  Task loss: 0.1921 | T: 272.71s
| It: 86001 | Rec. loss: 9.2311 |  Task loss: 0.1838 | T: 272.06s
| It: 87001 | Rec. loss: 9.2053 |  Task loss: 0.1976 | T: 274.58s
| It: 88001 | Rec. loss: 9.2121 |  Task loss: 0.1898 | T: 271.37s
| It: 89001 | Rec. loss: 9.1501 |  Task loss: 0.1983 | T: 272.24s
| It: 90001 | Rec. loss: 9.1410 |  Task loss: 0.1947 | T: 272.36s
| It: 91001 | Rec. loss: 9.1336 |  Task loss: 0.2127 | T: 272.86s
| It: 92001 | Rec. loss: 9.0732 |  Task loss: 0.1913 | T: 271.12s
| It: 93001 | Rec. loss: 9.0619 |  Task loss: 0.1912 | T: 273.19s
| It: 94001 | Rec. loss: 9.0195 |  Task loss: 0.1937 | T: 294.86s
| It: 95001 | Rec. loss: 8.9773 |  Task loss: 0.1969 | T: 273.20s
| It: 96001 | Rec. loss: 8.9615 |  Task loss: 0.1929 | T: 273.56s
| It: 97001 | Rec. loss: 8.9291 |  Task loss: 0.1891 | T: 273.24s
| It: 98001 | Rec. loss: 8.8914 |  Task loss: 0.1860 | T: 272.23s
| It: 99001 | Rec. loss: 8.8765 |  Task loss: 0.1890 | T: 271.37s
| It: 100001 | Rec. loss: 8.8536 |  Task loss: 0.1871 | T: 272.77s
| It: 101001 | Rec. loss: 8.8131 |  Task loss: 0.1933 | T: 270.14s
| It: 102001 | Rec. loss: 8.7950 |  Task loss: 0.2010 | T: 272.08s
| It: 103001 | Rec. loss: 8.7660 |  Task loss: 0.1917 | T: 272.35s
| It: 104001 | Rec. loss: 8.7177 |  Task loss: 0.1868 | T: 271.14s
| It: 105001 | Rec. loss: 8.7030 |  Task loss: 0.1899 | T: 272.86s
| It: 106001 | Rec. loss: 8.7054 |  Task loss: 0.1863 | T: 271.98s
| It: 107001 | Rec. loss: 8.6220 |  Task loss: 0.1788 | T: 272.94s
| It: 108001 | Rec. loss: 8.5970 |  Task loss: 0.1862 | T: 271.03s
| It: 109001 | Rec. loss: 8.5486 |  Task loss: 0.1767 | T: 273.43s
| It: 110001 | Rec. loss: 8.5249 |  Task loss: 0.1751 | T: 272.09s
| It: 111001 | Rec. loss: 8.4776 |  Task loss: 0.1690 | T: 272.77s
| It: 112001 | Rec. loss: 8.4483 |  Task loss: 0.1742 | T: 274.00s
| It: 113001 | Rec. loss: 8.4512 |  Task loss: 0.1742 | T: 273.35s
| It: 114001 | Rec. loss: 8.3822 |  Task loss: 0.1757 | T: 273.20s
| It: 115001 | Rec. loss: 8.3476 |  Task loss: 0.1873 | T: 271.58s
| It: 116001 | Rec. loss: 8.3056 |  Task loss: 0.1729 | T: 271.70s
| It: 117001 | Rec. loss: 8.3200 |  Task loss: 0.1747 | T: 272.28s
| It: 118001 | Rec. loss: 8.2335 |  Task loss: 0.1748 | T: 272.56s
| It: 119001 | Rec. loss: 8.1954 |  Task loss: 0.1756 | T: 273.10s
| It: 120001 | Rec. loss: 8.1550 |  Task loss: 0.1717 | T: 272.62s
| It: 121001 | Rec. loss: 8.1200 |  Task loss: 0.1701 | T: 272.97s
| It: 122001 | Rec. loss: 8.0808 |  Task loss: 0.1675 | T: 273.76s
| It: 123001 | Rec. loss: 8.0295 |  Task loss: 0.1671 | T: 274.17s
| It: 124001 | Rec. loss: 8.0133 |  Task loss: 0.1675 | T: 273.18s
| It: 125001 | Rec. loss: 7.9698 |  Task loss: 0.1761 | T: 273.51s
| It: 126001 | Rec. loss: 7.9319 |  Task loss: 0.1745 | T: 273.46s
| It: 127001 | Rec. loss: 7.8943 |  Task loss: 0.1722 | T: 272.39s
| It: 128001 | Rec. loss: 7.8596 |  Task loss: 0.1639 | T: 273.08s
| It: 129001 | Rec. loss: 7.8130 |  Task loss: 0.1658 | T: 273.24s
| It: 130001 | Rec. loss: 7.7539 |  Task loss: 0.1753 | T: 274.11s
| It: 131001 | Rec. loss: 7.7099 |  Task loss: 0.1664 | T: 271.76s
| It: 132001 | Rec. loss: 7.7122 |  Task loss: 0.1710 | T: 272.21s
| It: 133001 | Rec. loss: 7.6714 |  Task loss: 0.1728 | T: 271.57s
| It: 134001 | Rec. loss: 7.6163 |  Task loss: 0.1556 | T: 271.68s
| It: 135001 | Rec. loss: 7.5582 |  Task loss: 0.1585 | T: 297.81s
| It: 136001 | Rec. loss: 7.5040 |  Task loss: 0.1710 | T: 273.81s
| It: 137001 | Rec. loss: 7.4794 |  Task loss: 0.1634 | T: 272.81s
| It: 138001 | Rec. loss: 7.4186 |  Task loss: 0.1619 | T: 273.56s
| It: 139001 | Rec. loss: 7.3746 |  Task loss: 0.1604 | T: 272.82s
| It: 140001 | Rec. loss: 7.3338 |  Task loss: 0.1549 | T: 272.24s
| It: 141001 | Rec. loss: 7.2932 |  Task loss: 0.1605 | T: 273.91s
| It: 142001 | Rec. loss: 7.2264 |  Task loss: 0.1594 | T: 272.73s
| It: 143001 | Rec. loss: 7.1980 |  Task loss: 0.1663 | T: 271.60s
| It: 144001 | Rec. loss: 7.1384 |  Task loss: 0.1601 | T: 272.35s
| It: 145001 | Rec. loss: 7.0813 |  Task loss: 0.1565 | T: 272.45s
| It: 146001 | Rec. loss: 7.0387 |  Task loss: 0.1538 | T: 273.04s
| It: 147001 | Rec. loss: 6.9865 |  Task loss: 0.1674 | T: 272.43s
| It: 148001 | Rec. loss: 6.9335 |  Task loss: 0.1694 | T: 271.19s
| It: 149001 | Rec. loss: 6.9270 |  Task loss: 0.1528 | T: 272.57s
| It: 150001 | Rec. loss: 6.8404 |  Task loss: 0.1648 | T: 272.28s
| It: 151001 | Rec. loss: 6.7856 |  Task loss: 0.1635 | T: 271.96s
| It: 152001 | Rec. loss: 6.7335 |  Task loss: 0.1602 | T: 272.55s
| It: 153001 | Rec. loss: 6.6885 |  Task loss: 0.1523 | T: 271.58s
| It: 154001 | Rec. loss: 6.6512 |  Task loss: 0.1459 | T: 272.51s
| It: 155001 | Rec. loss: 6.5807 |  Task loss: 0.1469 | T: 272.41s
| It: 156001 | Rec. loss: 6.5219 |  Task loss: 0.1436 | T: 271.84s
| It: 157001 | Rec. loss: 6.4722 |  Task loss: 0.1545 | T: 272.70s
| It: 158001 | Rec. loss: 6.4206 |  Task loss: 0.1478 | T: 273.61s
| It: 159001 | Rec. loss: 6.3570 |  Task loss: 0.1501 | T: 272.89s
| It: 160001 | Rec. loss: 6.3107 |  Task loss: 0.1472 | T: 272.82s
| It: 161001 | Rec. loss: 6.2528 |  Task loss: 0.1414 | T: 272.73s
| It: 162001 | Rec. loss: 6.1982 |  Task loss: 0.1386 | T: 273.07s
| It: 163001 | Rec. loss: 6.1772 |  Task loss: 0.1404 | T: 273.57s
| It: 164001 | Rec. loss: 6.0788 |  Task loss: 0.1395 | T: 272.03s
| It: 165001 | Rec. loss: 6.0237 |  Task loss: 0.1417 | T: 273.72s
| It: 166001 | Rec. loss: 5.9774 |  Task loss: 0.1455 | T: 272.52s
| It: 167001 | Rec. loss: 5.9014 |  Task loss: 0.1453 | T: 274.25s
| It: 168001 | Rec. loss: 5.8525 |  Task loss: 0.1444 | T: 272.84s
| It: 169001 | Rec. loss: 5.7909 |  Task loss: 0.1413 | T: 271.79s
| It: 170001 | Rec. loss: 5.7206 |  Task loss: 0.1458 | T: 272.38s
| It: 171001 | Rec. loss: 5.6641 |  Task loss: 0.1423 | T: 272.07s
| It: 172001 | Rec. loss: 5.6371 |  Task loss: 0.1385 | T: 272.08s
| It: 173001 | Rec. loss: 5.5405 |  Task loss: 0.1407 | T: 272.94s
| It: 174001 | Rec. loss: 5.4844 |  Task loss: 0.1385 | T: 273.93s
| It: 175001 | Rec. loss: 5.4200 |  Task loss: 0.1375 | T: 286.45s
| It: 176001 | Rec. loss: 5.3519 |  Task loss: 0.1384 | T: 283.55s
| It: 177001 | Rec. loss: 5.2881 |  Task loss: 0.1352 | T: 272.32s
| It: 178001 | Rec. loss: 5.2083 |  Task loss: 0.1396 | T: 272.55s
| It: 179001 | Rec. loss: 5.1603 |  Task loss: 0.1347 | T: 274.48s
| It: 180001 | Rec. loss: 5.0947 |  Task loss: 0.1337 | T: 272.41s
| It: 181001 | Rec. loss: 5.0199 |  Task loss: 0.1323 | T: 272.42s
| It: 182001 | Rec. loss: 4.9627 |  Task loss: 0.1310 | T: 273.86s
| It: 183001 | Rec. loss: 4.8871 |  Task loss: 0.1313 | T: 273.56s
| It: 184001 | Rec. loss: 4.8137 |  Task loss: 0.1335 | T: 273.76s
| It: 185001 | Rec. loss: 4.7643 |  Task loss: 0.1318 | T: 271.73s
| It: 186001 | Rec. loss: 4.6831 |  Task loss: 0.1370 | T: 273.11s
| It: 187001 | Rec. loss: 4.6200 |  Task loss: 0.1317 | T: 272.59s
| It: 188001 | Rec. loss: 4.5639 |  Task loss: 0.1301 | T: 273.32s
| It: 189001 | Rec. loss: 4.4805 |  Task loss: 0.1342 | T: 273.30s
| It: 190001 | Rec. loss: 4.4152 |  Task loss: 0.1370 | T: 272.36s
| It: 191001 | Rec. loss: 4.3469 |  Task loss: 0.1368 | T: 273.03s
| It: 192001 | Rec. loss: 4.2837 |  Task loss: 0.1345 | T: 273.99s
| It: 193001 | Rec. loss: 4.2063 |  Task loss: 0.1291 | T: 273.38s
| It: 194001 | Rec. loss: 4.1358 |  Task loss: 0.1341 | T: 273.82s
| It: 195001 | Rec. loss: 4.0706 |  Task loss: 0.1353 | T: 274.63s
| It: 196001 | Rec. loss: 3.9955 |  Task loss: 0.1311 | T: 279.75s
| It: 197001 | Rec. loss: 3.9256 |  Task loss: 0.1290 | T: 280.81s
| It: 198001 | Rec. loss: 3.8469 |  Task loss: 0.1313 | T: 278.60s
| It: 199001 | Rec. loss: 3.7875 |  Task loss: 0.1336 | T: 279.51s
| It: 200001 | Rec. loss: 3.7122 |  Task loss: 0.1261 | T: 271.71s
| It: 201001 | Rec. loss: 3.6477 |  Task loss: 0.1267 | T: 272.26s
| It: 202001 | Rec. loss: 3.5820 |  Task loss: 0.1282 | T: 271.74s
| It: 203001 | Rec. loss: 3.5186 |  Task loss: 0.1259 | T: 272.18s
| It: 204001 | Rec. loss: 3.4539 |  Task loss: 0.1262 | T: 271.92s
| It: 205001 | Rec. loss: 3.3735 |  Task loss: 0.1252 | T: 272.22s
| It: 206001 | Rec. loss: 3.3185 |  Task loss: 0.1246 | T: 272.15s
| It: 207001 | Rec. loss: 3.2560 |  Task loss: 0.1229 | T: 273.24s
| It: 208001 | Rec. loss: 3.1926 |  Task loss: 0.1241 | T: 273.36s
| It: 209001 | Rec. loss: 3.1325 |  Task loss: 0.1222 | T: 274.31s
| It: 210001 | Rec. loss: 3.0663 |  Task loss: 0.1229 | T: 273.06s
| It: 211001 | Rec. loss: 3.0069 |  Task loss: 0.1219 | T: 272.27s
| It: 212001 | Rec. loss: 2.9440 |  Task loss: 0.1213 | T: 270.67s
| It: 213001 | Rec. loss: 2.8948 |  Task loss: 0.1189 | T: 272.78s
| It: 214001 | Rec. loss: 2.8345 |  Task loss: 0.1183 | T: 272.24s
| It: 215001 | Rec. loss: 2.7861 |  Task loss: 0.1205 | T: 273.54s
| It: 216001 | Rec. loss: 2.7206 |  Task loss: 0.1178 | T: 297.15s
| It: 217001 | Rec. loss: 2.6705 |  Task loss: 0.1144 | T: 272.49s
| It: 218001 | Rec. loss: 2.6162 |  Task loss: 0.1161 | T: 272.95s
| It: 219001 | Rec. loss: 2.5627 |  Task loss: 0.1169 | T: 271.41s
| It: 220001 | Rec. loss: 2.5170 |  Task loss: 0.1140 | T: 272.39s
| It: 221001 | Rec. loss: 2.4705 |  Task loss: 0.1129 | T: 272.81s
| It: 222001 | Rec. loss: 2.4213 |  Task loss: 0.1165 | T: 273.94s
| It: 223001 | Rec. loss: 2.3740 |  Task loss: 0.1159 | T: 273.40s
| It: 224001 | Rec. loss: 2.3263 |  Task loss: 0.1142 | T: 273.46s
| It: 225001 | Rec. loss: 2.2852 |  Task loss: 0.1114 | T: 272.49s
| It: 226001 | Rec. loss: 2.2444 |  Task loss: 0.1109 | T: 272.11s
| It: 227001 | Rec. loss: 2.1915 |  Task loss: 0.1106 | T: 271.73s
| It: 228001 | Rec. loss: 2.1547 |  Task loss: 0.1097 | T: 272.73s
| It: 229001 | Rec. loss: 2.1102 |  Task loss: 0.1094 | T: 272.86s
| It: 230001 | Rec. loss: 2.0687 |  Task loss: 0.1097 | T: 272.36s
| It: 231001 | Rec. loss: 2.0245 |  Task loss: 0.1055 | T: 269.72s
| It: 232001 | Rec. loss: 1.9845 |  Task loss: 0.1061 | T: 270.22s
| It: 233001 | Rec. loss: 1.9470 |  Task loss: 0.1068 | T: 271.07s
| It: 234001 | Rec. loss: 1.9089 |  Task loss: 0.1050 | T: 272.64s
| It: 235001 | Rec. loss: 1.8732 |  Task loss: 0.1066 | T: 272.12s
| It: 236001 | Rec. loss: 1.8352 |  Task loss: 0.1053 | T: 272.42s
| It: 237001 | Rec. loss: 1.7995 |  Task loss: 0.1062 | T: 272.82s
| It: 238001 | Rec. loss: 1.7603 |  Task loss: 0.1021 | T: 273.03s
| It: 239001 | Rec. loss: 1.7267 |  Task loss: 0.1025 | T: 273.20s
| It: 240001 | Rec. loss: 1.6899 |  Task loss: 0.1024 | T: 272.80s
| It: 241001 | Rec. loss: 1.6577 |  Task loss: 0.1004 | T: 272.21s
| It: 242001 | Rec. loss: 1.6249 |  Task loss: 0.1012 | T: 273.59s
| It: 243001 | Rec. loss: 1.5943 |  Task loss: 0.0994 | T: 271.80s
| It: 244001 | Rec. loss: 1.5617 |  Task loss: 0.0988 | T: 271.55s
| It: 245001 | Rec. loss: 1.5326 |  Task loss: 0.0997 | T: 273.68s
| It: 246001 | Rec. loss: 1.4971 |  Task loss: 0.0999 | T: 273.20s
| It: 247001 | Rec. loss: 1.4703 |  Task loss: 0.0978 | T: 274.13s
| It: 248001 | Rec. loss: 1.4384 |  Task loss: 0.0969 | T: 273.15s
| It: 249001 | Rec. loss: 1.4106 |  Task loss: 0.0976 | T: 273.25s
| It: 250001 | Rec. loss: 1.3851 |  Task loss: 0.0975 | T: 270.91s
| It: 251001 | Rec. loss: 1.3588 |  Task loss: 0.0972 | T: 272.73s
| It: 252001 | Rec. loss: 1.3279 |  Task loss: 0.0949 | T: 272.16s
| It: 253001 | Rec. loss: 1.3037 |  Task loss: 0.0939 | T: 272.67s
| It: 254001 | Rec. loss: 1.2800 |  Task loss: 0.0918 | T: 273.20s
| It: 255001 | Rec. loss: 1.2512 |  Task loss: 0.0942 | T: 272.85s
| It: 256001 | Rec. loss: 1.2230 |  Task loss: 0.0933 | T: 275.94s
| It: 257001 | Rec. loss: 1.2010 |  Task loss: 0.0920 | T: 295.47s
| It: 258001 | Rec. loss: 1.1778 |  Task loss: 0.0926 | T: 275.03s
| It: 259001 | Rec. loss: 1.1534 |  Task loss: 0.0915 | T: 272.58s
| It: 260001 | Rec. loss: 1.1329 |  Task loss: 0.0905 | T: 274.70s
| It: 261001 | Rec. loss: 1.1116 |  Task loss: 0.0902 | T: 273.80s
| It: 262001 | Rec. loss: 1.0878 |  Task loss: 0.0900 | T: 273.39s
| It: 263001 | Rec. loss: 1.0629 |  Task loss: 0.0900 | T: 273.93s
| It: 264001 | Rec. loss: 1.0433 |  Task loss: 0.0890 | T: 272.75s
| It: 265001 | Rec. loss: 1.0221 |  Task loss: 0.0889 | T: 274.32s
| It: 266001 | Rec. loss: 0.9996 |  Task loss: 0.0888 | T: 272.56s
| It: 267001 | Rec. loss: 0.9800 |  Task loss: 0.0874 | T: 272.88s
| It: 268001 | Rec. loss: 0.9636 |  Task loss: 0.0878 | T: 273.59s
| It: 269001 | Rec. loss: 0.9420 |  Task loss: 0.0863 | T: 272.00s
| It: 270001 | Rec. loss: 0.9289 |  Task loss: 0.0865 | T: 273.24s
| It: 271001 | Rec. loss: 0.9057 |  Task loss: 0.0872 | T: 273.78s
| It: 272001 | Rec. loss: 0.8890 |  Task loss: 0.0860 | T: 271.98s
| It: 273001 | Rec. loss: 0.8681 |  Task loss: 0.0854 | T: 272.17s
| It: 274001 | Rec. loss: 0.8537 |  Task loss: 0.0857 | T: 271.67s
| It: 275001 | Rec. loss: 0.8338 |  Task loss: 0.0853 | T: 272.41s
| It: 276001 | Rec. loss: 0.8190 |  Task loss: 0.0846 | T: 271.41s
| It: 277001 | Rec. loss: 0.8058 |  Task loss: 0.0846 | T: 272.65s
| It: 278001 | Rec. loss: 0.7928 |  Task loss: 0.0836 | T: 271.05s
| It: 279001 | Rec. loss: 0.7713 |  Task loss: 0.0835 | T: 273.33s
| It: 280001 | Rec. loss: 0.7576 |  Task loss: 0.0832 | T: 274.05s
| It: 281001 | Rec. loss: 0.7440 |  Task loss: 0.0830 | T: 273.28s
| It: 282001 | Rec. loss: 0.7298 |  Task loss: 0.0826 | T: 273.52s
| It: 283001 | Rec. loss: 0.7137 |  Task loss: 0.0826 | T: 273.40s
| It: 284001 | Rec. loss: 0.7003 |  Task loss: 0.0826 | T: 272.95s
| It: 285001 | Rec. loss: 0.6875 |  Task loss: 0.0821 | T: 272.22s
| It: 286001 | Rec. loss: 0.6767 |  Task loss: 0.0824 | T: 272.34s
| It: 287001 | Rec. loss: 0.6648 |  Task loss: 0.0822 | T: 271.87s
| It: 288001 | Rec. loss: 0.6514 |  Task loss: 0.0819 | T: 272.22s
| It: 289001 | Rec. loss: 0.6405 |  Task loss: 0.0820 | T: 271.42s
| It: 290001 | Rec. loss: 0.6296 |  Task loss: 0.0819 | T: 272.26s
| It: 291001 | Rec. loss: 0.6179 |  Task loss: 0.0819 | T: 272.36s
| It: 292001 | Rec. loss: 0.6069 |  Task loss: 0.0817 | T: 271.66s
| It: 293001 | Rec. loss: 0.5965 |  Task loss: 0.0819 | T: 271.25s
| It: 294001 | Rec. loss: 0.5871 |  Task loss: 0.0817 | T: 273.48s
| It: 295001 | Rec. loss: 0.5774 |  Task loss: 0.0815 | T: 272.96s
| It: 296001 | Rec. loss: 0.5685 |  Task loss: 0.0815 | T: 272.17s
| It: 297001 | Rec. loss: 0.5598 |  Task loss: 0.0814 | T: 297.64s
| It: 298001 | Rec. loss: 0.5518 |  Task loss: 0.0815 | T: 273.72s
| It: 299001 | Rec. loss: 0.5443 |  Task loss: 0.0816 | T: 272.70s
| It: 300001 | Rec. loss: 0.5370 |  Task loss: 0.0815 | T: 272.69s
| It: 301001 | Rec. loss: 0.5297 |  Task loss: 0.0815 | T: 271.97s
| It: 302001 | Rec. loss: 0.5225 |  Task loss: 0.0815 | T: 274.30s
| It: 303001 | Rec. loss: 0.5163 |  Task loss: 0.0815 | T: 273.53s
| It: 304001 | Rec. loss: 0.5104 |  Task loss: 0.0814 | T: 271.70s
| It: 305001 | Rec. loss: 0.5047 |  Task loss: 0.0814 | T: 272.48s
| It: 306001 | Rec. loss: 0.4995 |  Task loss: 0.0814 | T: 272.90s
| It: 307001 | Rec. loss: 0.4947 |  Task loss: 0.0814 | T: 274.27s
| It: 308001 | Rec. loss: 0.4903 |  Task loss: 0.0815 | T: 273.43s
| It: 309001 | Rec. loss: 0.4861 |  Task loss: 0.0815 | T: 274.62s
| It: 310001 | Rec. loss: 0.4821 |  Task loss: 0.0816 | T: 273.28s
| It: 311001 | Rec. loss: 0.4787 |  Task loss: 0.0815 | T: 272.98s
| It: 312001 | Rec. loss: 0.4752 |  Task loss: 0.0814 | T: 274.26s
| It: 313001 | Rec. loss: 0.4724 |  Task loss: 0.0814 | T: 273.21s
| It: 314001 | Rec. loss: 0.4697 |  Task loss: 0.0814 | T: 273.32s
| It: 315001 | Rec. loss: 0.4676 |  Task loss: 0.0814 | T: 272.03s
| It: 316001 | Rec. loss: 0.4657 |  Task loss: 0.0814 | T: 273.43s
| It: 317001 | Rec. loss: 0.4644 |  Task loss: 0.0814 | T: 272.23s
| It: 318001 | Rec. loss: 0.4635 |  Task loss: 0.0814 | T: 271.93s
| It: 319001 | Rec. loss: 0.4631 |  Task loss: 0.0814 | T: 272.33s
| It: 320000 | Rec. loss: 0.4630 |  Task loss: 0.0814 | T: 274.05s
Optimal candidate solution with rec. loss 1067.0776 selected.
Reconstruction stats:
Starting evaluations for attack effectiveness report...
/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
The size of tensor a (55) must match the size of tensor b (61) at non-singleton dimension 3
None
Saved to /user/gparrella/breaching/my_test/optimization_based/grad_inversion/results/vggface2_flickr_16_post2_1.png
========================================================================

